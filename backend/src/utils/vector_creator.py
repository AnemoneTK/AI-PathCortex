# backend/src/utils/vector_creator.py
import os
import json
import shutil
import faiss
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
from sentence_transformers import SentenceTransformer
from colorama import init, Fore, Style

# ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô colorama
init(autoreset=True)

class VectorCreator:
    """
    ‡∏Ñ‡∏•‡∏≤‡∏™‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á vector embeddings ‡πÅ‡∏•‡∏∞‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• FAISS
    ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢ semantic search
    """
    def __init__(self, 
                processed_data_dir: str, 
                vector_db_dir: str,
                embedding_model=None,
                clear_vector_db: bool = True):
        """
        ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö VectorCreator
        
        Args:
            processed_data_dir: ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß
            vector_db_dir: ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏Å‡πá‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• vector
            embedding_model: ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á embedding ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡∏•‡∏≠‡∏á
            clear_vector_db: ‡∏•‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• vector ‡πÄ‡∏î‡∏¥‡∏°‡∏Å‡πà‡∏≠‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà
        """
        self.processed_data_dir = Path(processed_data_dir)
        self.vector_db_dir = Path(vector_db_dir)
        self.embedding_model = embedding_model
        
        # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏¢‡πà‡∏≠‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        self.job_vector_dir = self.vector_db_dir / "job_knowledge"
        self.advice_vector_dir = self.vector_db_dir / "career_advice"
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
        self.job_vector_dir.mkdir(parents=True, exist_ok=True)
        self.advice_vector_dir.mkdir(parents=True, exist_ok=True)
        
        # ‡πÑ‡∏ü‡∏•‡πå FAISS index ‡πÅ‡∏•‡∏∞ metadata
        self.job_index_path = self.job_vector_dir / "faiss_index.bin"
        self.job_metadata_path = self.job_vector_dir / "metadata.json"
        
        self.advice_index_path = self.advice_vector_dir / "faiss_index.bin"
        self.advice_metadata_path = self.advice_vector_dir / "metadata.json"
        
        # ‡∏•‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• vector ‡πÄ‡∏î‡∏¥‡∏°‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
        if clear_vector_db:
            self._clear_vector_database()
        
        print(f"{Fore.CYAN}VectorCreator ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
        print(f"{Fore.CYAN}üìÇ ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß: {self.processed_data_dir}")
        print(f"{Fore.CYAN}üìÇ ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• vector: {self.vector_db_dir}")
        print(f"{Fore.CYAN}ü§ñ ‡πÇ‡∏°‡πÄ‡∏î‡∏• Embedding: {type(self.embedding_model).__name__ if self.embedding_model else '‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏∞‡∏ö‡∏∏ (‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡∏•‡∏≠‡∏á)'}") 
    
    def _clear_vector_database(self) -> None:
        """‡∏•‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• vector ‡πÄ‡∏î‡∏¥‡∏°"""
        print(f"{Fore.YELLOW}‚ÑπÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏•‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• vector ‡πÄ‡∏î‡∏¥‡∏°...")
        
        # ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå FAISS index ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà
        if self.job_index_path.exists():
            os.remove(self.job_index_path)
            print(f"{Fore.GREEN}‚úÖ ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå {self.job_index_path} ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
        
        if self.job_metadata_path.exists():
            os.remove(self.job_metadata_path)
            print(f"{Fore.GREEN}‚úÖ ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå {self.job_metadata_path} ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
        
        if self.advice_index_path.exists():
            os.remove(self.advice_index_path)
            print(f"{Fore.GREEN}‚úÖ ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå {self.advice_index_path} ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
        
        if self.advice_metadata_path.exists():
            os.remove(self.advice_metadata_path)
            print(f"{Fore.GREEN}‚úÖ ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå {self.advice_metadata_path} ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
    
    def _create_mock_embedding(self, text: str, dimension: int = 384) -> np.ndarray:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á embedding ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÉ‡∏ô‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏• Embedding
        
        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á embedding
            dimension: ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á vector (default: 384 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö MiniLM)
            
        Returns:
            numpy array ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô embedding
        """
        # ‡πÉ‡∏ä‡πâ hash ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
        np.random.seed(hash(text) % 2**32)
        vector = np.random.random(dimension).astype(np.float32)
        # Normalize vector ‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö 1
        return vector / np.linalg.norm(vector)
    
    def _get_embedding(self, text: str, dimension: int = 384) -> np.ndarray:
        if self.embedding_model:
            # Ensure normalization
            embedding = self.embedding_model.encode(text)
            return embedding / np.linalg.norm(embedding)
        else:
            return self._create_mock_embedding(text, dimension)
    
    def _load_job_data(self) -> List[Dict[str, Any]]:
        """
        ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡πâ‡∏ß
        
        Returns:
            List ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
        """
        cleaned_jobs_dir = self.processed_data_dir / "cleaned_jobs"
        job_files = list(cleaned_jobs_dir.glob("*.json"))
        
        if not job_files:
            print(f"{Fore.RED}‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡πÉ‡∏ô {cleaned_jobs_dir}")
            return []
        
        print(f"{Fore.CYAN}üìö ‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û {len(job_files)} ‡πÑ‡∏ü‡∏•‡πå")
        
        job_data = []
        for file_path in job_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    job_data.append(data)
            except Exception as e:
                print(f"{Fore.RED}‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå {file_path}: {str(e)}")
        
        print(f"{Fore.GREEN}‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(job_data)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        return job_data
    
    def _load_career_advice_data(self) -> List[Dict[str, Any]]:
        """
        ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
        
        Returns:
            List ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
        """
        advice_file = self.processed_data_dir / "career_advices" / "career_advices.json"
        
        if not advice_file.exists():
            print(f"{Fore.RED}‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏ó‡∏µ‡πà {advice_file}")
            return []
        
        try:
            with open(advice_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
                if isinstance(data, dict) and "career_advices" in data:
                    advices = data["career_advices"]
                    print(f"{Fore.GREEN}‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(advices)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
                    return advices
                elif isinstance(data, list):
                    print(f"{Fore.GREEN}‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(data)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
                    return data
                else:
                    print(f"{Fore.RED}‚ùå ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
                    return []
        except Exception as e:
            print(f"{Fore.RED}‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå {advice_file}: {str(e)}")
            return []
    
    def _prepare_job_text_for_embedding(self, job: Dict[str, Any]) -> str:
        """
        ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á embedding
        
        Args:
            job: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
            
        Returns:
            ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á embedding
        """
        text_parts = []
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô
        if "titles" in job and job["titles"]:
            text_parts.append(f"‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô: {', '.join(job['titles'])}")
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢
        if "description" in job and job["description"]:
            text_parts.append(f"‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢: {job['description']}")
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏±‡∏ö‡∏ú‡∏¥‡∏î‡∏ä‡∏≠‡∏ö
        if "responsibilities" in job and job["responsibilities"]:
            resp_text = " ".join(f"- {resp}" for resp in job["responsibilities"])
            text_parts.append(f"‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏±‡∏ö‡∏ú‡∏¥‡∏î‡∏ä‡∏≠‡∏ö: {resp_text}")
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ó‡∏±‡∏Å‡∏©‡∏∞
        if "skills" in job and job["skills"]:
            skills_text = ", ".join(job["skills"])
            text_parts.append(f"‡∏ó‡∏±‡∏Å‡∏©‡∏∞: {skills_text}")
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå
        if "salary_ranges" in job and job["salary_ranges"]:
            salary_info = []
            for salary_range in job["salary_ranges"]:
                if "experience" in salary_range and "salary" in salary_range:
                    salary_info.append(f"‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå {salary_range['experience']} ‡∏õ‡∏µ: ‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô {salary_range['salary']} ‡∏ö‡∏≤‡∏ó")
            
            if salary_info:
                text_parts.append(f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô: {' '.join(salary_info)}")
        
        # ‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
        return " ".join(text_parts)
    
    def _prepare_advice_text_for_embedding(self, advice: Dict[str, Any]) -> str:
        text_parts = []
        
        # ‡πÄ‡∏ô‡πâ‡∏ô‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠
        if "title" in advice and advice["title"]:
            text_parts.append(f"‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠: {advice['title']} " * 3)
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤
        if "content" in advice and advice["content"]:
            text_parts.append(f"‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤: {advice['content']}")
        
        # ‡πÄ‡∏ô‡πâ‡∏ô‡πÅ‡∏ó‡πá‡∏Å
        if "tags" in advice and advice["tags"]:
            tags_text = ", ".join(advice["tags"])
            text_parts.append(f"‡πÅ‡∏ó‡πá‡∏Å: {tags_text} " * 2)
        
        return " ".join(text_parts)
    
    def create_job_embeddings(self) -> Dict[str, Any]:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡πÉ‡∏ô FAISS
        
        Returns:
            ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings
        """
        result = {
            "success": False,
            "vectors_count": 0,
            "error": None
        }
        
        try:
            # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
            job_data = self._load_job_data()
            
            if not job_data:
                result["error"] = "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û"
                return result
            
            print(f"{Fore.CYAN}üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û {len(job_data)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£...")
            
            # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings
            job_ids = []
            job_texts = []
            job_ids_to_index = {}
            
            for job in job_data:
                if "id" not in job:
                    continue
                
                job_text = self._prepare_job_text_for_embedding(job)
                job_texts.append(job_text)
                job_ids.append(job["id"])
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            if not job_texts:
                result["error"] = "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡πÑ‡∏î‡πâ"
                return result
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings
            print(f"{Fore.CYAN}üß† ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô {len(job_texts)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£...")
            
            if self.embedding_model:
                # ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏£‡∏¥‡∏á
                embeddings = self.embedding_model.encode(job_texts, show_progress_bar=True)
            else:
                # ‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡∏•‡∏≠‡∏á
                print(f"{Fore.YELLOW}‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• embedding ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡∏•‡∏≠‡∏á")
                embeddings = np.array([self._get_embedding(text) for text in job_texts])
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á FAISS index
            print(f"{Fore.CYAN}üìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á FAISS index...")
            
            dimension = embeddings.shape[1]
            index = faiss.IndexFlatL2(dimension)
            index.add(embeddings.astype(np.float32))
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á mapping ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á job_id ‡∏Å‡∏±‡∏ö index
            for i, job_id in enumerate(job_ids):
                job_ids_to_index[job_id] = i
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å FAISS index
            print(f"{Fore.CYAN}üíæ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å FAISS index ‡πÑ‡∏õ‡∏ó‡∏µ‡πà {self.job_index_path}...")
            faiss.write_index(index, str(self.job_index_path))
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å metadata
            print(f"{Fore.CYAN}üíæ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å metadata ‡πÑ‡∏õ‡∏ó‡∏µ‡πà {self.job_metadata_path}...")
            metadata = {
                "job_ids": job_ids,
                "job_ids_to_index": job_ids_to_index,
                "job_data": job_data
            }
            
            with open(self.job_metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            print(f"{Fore.GREEN}‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(job_ids)} vectors")
            
            result["success"] = True
            result["vectors_count"] = len(job_ids)
            
            return result
            
        except Exception as e:
            print(f"{Fore.RED}‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û: {str(e)}")
            result["error"] = str(e)
            return result
    
    def create_advice_embeddings(self) -> Dict[str, Any]:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡πÉ‡∏ô FAISS
        
        Returns:
            ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings
        """
        result = {
            "success": False,
            "vectors_count": 0,
            "error": None
        }
        
        try:
            # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
            advice_data = self._load_career_advice_data()
            
            if not advice_data:
                result["error"] = "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û"
                return result
            
            print(f"{Fore.CYAN}üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û {len(advice_data)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£...")
            
            # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings
            advice_ids = []
            advice_texts = []
            advice_ids_to_index = {}
            
            for i, advice in enumerate(advice_data):
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö ID
                if "id" not in advice:
                    advice["id"] = f"advice_{i}"
                
                advice_text = self._prepare_advice_text_for_embedding(advice)
                advice_texts.append(advice_text)
                advice_ids.append(advice["id"])
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            if not advice_texts:
                result["error"] = "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡πÑ‡∏î‡πâ"
                return result
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings
            print(f"{Fore.CYAN}üß† ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô {len(advice_texts)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£...")
            
            if self.embedding_model:
                # ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏£‡∏¥‡∏á
                embeddings = self.embedding_model.encode(advice_texts, show_progress_bar=True)
            else:
                # ‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡∏•‡∏≠‡∏á
                print(f"{Fore.YELLOW}‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• embedding ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡∏•‡∏≠‡∏á")
                embeddings = np.array([self._get_embedding(text) for text in advice_texts])
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á FAISS index
            print(f"{Fore.CYAN}üìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á FAISS index...")
            
            dimension = embeddings.shape[1]
            index = faiss.IndexFlatL2(dimension)
            index.add(embeddings.astype(np.float32))
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á mapping ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á advice_id ‡∏Å‡∏±‡∏ö index
            for i, advice_id in enumerate(advice_ids):
                advice_ids_to_index[advice_id] = i
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å FAISS index
            print(f"{Fore.CYAN}üíæ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å FAISS index ‡πÑ‡∏õ‡∏ó‡∏µ‡πà {self.advice_index_path}...")
            faiss.write_index(index, str(self.advice_index_path))
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å metadata
            print(f"{Fore.CYAN}üíæ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å metadata ‡πÑ‡∏õ‡∏ó‡∏µ‡πà {self.advice_metadata_path}...")
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• metadata ‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö
            simplified_advice_data = []
            for advice in advice_data:
                simplified = {
                    "id": advice["id"],
                    "title": advice.get("title", ""),
                    "tags": advice.get("tags", []),
                    "source": advice.get("source", ""),
                    "url": advice.get("url", "")
                }
                
                # ‡∏î‡∏∂‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
                if "content" in advice:
                    simplified["text"] = advice["content"][:500] + "..." if len(advice["content"]) > 500 else advice["content"]
                elif "paragraphs" in advice and advice["paragraphs"]:
                    joined_text = " ".join(advice["paragraphs"][:3])
                    simplified["text"] = joined_text[:500] + "..." if len(joined_text) > 500 else joined_text
                
                simplified_advice_data.append(simplified)
            
            metadata = {
                "advice_ids": advice_ids,
                "advice_ids_to_index": advice_ids_to_index,
                "advice_data": simplified_advice_data
            }
            
            with open(self.advice_metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            print(f"{Fore.GREEN}‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(advice_ids)} vectors")
            
            result["success"] = True
            result["vectors_count"] = len(advice_ids)
            
            return result
            
        except Exception as e:
            print(f"{Fore.RED}‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û: {str(e)}")
            result["error"] = str(e)
            return result
    
    def create_all_embeddings(self) -> Dict[str, Any]:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡∏ó‡∏±‡πâ‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
        
        Returns:
            ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings
        """
        print(f"{Fore.CYAN}{'='*60}")
        print(f"{Fore.CYAN}= ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Vector Database ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î")
        print(f"{Fore.CYAN}{'='*60}")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
        print(f"\n{Fore.CYAN}{'='*20} ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û {'='*20}")
        job_result = self.create_job_embeddings()
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
        print(f"\n{Fore.CYAN}{'='*20} ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û {'='*20}")
        advice_result = self.create_advice_embeddings()
        
        return {
            "job_embeddings": job_result,
            "advice_embeddings": advice_result
        }
    
    def search_similar_jobs(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """
        ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
        
        Args:
            query: ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
            k: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
            
        Returns:
            ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
        """
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ vector database ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á
        if not self.job_index_path.exists() or not self.job_metadata_path.exists():
            print(f"{Fore.RED}‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö vector database ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û")
            return []
        
        try:
            # ‡πÇ‡∏´‡∏•‡∏î FAISS index
            index = faiss.read_index(str(self.job_index_path))
            
            # ‡πÇ‡∏´‡∏•‡∏î metadata
            with open(self.job_metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á embedding ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
            query_embedding = None
            if self.embedding_model:
                query_embedding = self.embedding_model.encode([query])[0]
            else:
                query_embedding = self._get_embedding(query)
            
            # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÉ‡∏ô FAISS
            query_embedding = np.array([query_embedding]).astype(np.float32)
            distances, indices = index.search(query_embedding, k)
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            results = []
            for i, idx in enumerate(indices[0]):
                if idx == -1 or idx >= len(metadata["job_ids"]):
                    continue
                
                job_id = metadata["job_ids"][idx]
                job_data = None
                
                # ‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏à‡∏≤‡∏Å job_id
                for job in metadata["job_data"]:
                    if job["id"] == job_id:
                        job_data = job
                        break
                
                if job_data is None:
                    continue
                
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á (1 - ‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á)
                similarity = 1.0 / (1.0 + distances[0][i])
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                result = {
                    "id": job_id,
                    "title": job_data["titles"][0] if job_data["titles"] else job_id,
                    "similarity": similarity,
                    "description": job_data.get("description", ""),
                    "responsibilities": job_data.get("responsibilities", []),
                    "skills": job_data.get("skills", []),
                }
                
                results.append(result)
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
                print(f"{i+1}. {Fore.GREEN}{result['title']}{Style.RESET_ALL} " + 
                     f"(‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô: {Fore.YELLOW}{result['similarity']:.2f}{Style.RESET_ALL})")
            
            return results
        
        except Exception as e:
            print(f"{Fore.RED}‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏≠‡∏≤‡∏ä‡∏µ‡∏û: {str(e)}")
            return []
    
    def search_relevant_advices(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """
        ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
        
        Args:
            query: ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
            k: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
            
        Returns:
            ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
        """
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ vector database ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á
        if not self.advice_index_path.exists() or not self.advice_metadata_path.exists():
            print(f"{Fore.RED}‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö vector database ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û")
            return []
        
        try:
            # ‡πÇ‡∏´‡∏•‡∏î FAISS index
            index = faiss.read_index(str(self.advice_index_path))
            
            # ‡πÇ‡∏´‡∏•‡∏î metadata
            with open(self.advice_metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á embedding ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
            query_embedding = None
            if self.embedding_model:
                query_embedding = self.embedding_model.encode([query])[0]
            else:
                query_embedding = self._get_embedding(query)
            
            # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÉ‡∏ô FAISS
            query_embedding = np.array([query_embedding]).astype(np.float32)
            distances, indices = index.search(query_embedding, k)
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            results = []
            for i, idx in enumerate(indices[0]):
                if idx == -1 or idx >= len(metadata["advice_ids"]):
                    continue
                
                advice_id = metadata["advice_ids"][idx]
                advice_data = None
                
                # ‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏à‡∏≤‡∏Å advice_id
                for advice in metadata["advice_data"]:
                    if advice["id"] == advice_id:
                        advice_data = advice
                        break
                
                if advice_data is None:
                    continue
                
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á (1 - ‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á)
                similarity = 1.0 / (1.0 + distances[0][i])
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                result = {
                    "id": advice_id,
                    "title": advice_data.get("title", ""),
                    "similarity": similarity,
                    "text": advice_data.get("text", ""),
                    "tags": advice_data.get("tags", []),
                    "source": advice_data.get("source", ""),
                    "url": advice_data.get("url", "")
                }
                
                results.append(result)
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
                tags_str = f", ‡πÅ‡∏ó‡πá‡∏Å: {', '.join(result['tags'])}" if result['tags'] else ""
                print(f"{i+1}. {Fore.GREEN}{result['title']}{Style.RESET_ALL} " + 
                    f"(‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô: {Fore.YELLOW}{result['similarity']:.2f}{Style.RESET_ALL}{tags_str})")
            
            return results
        
        except Exception as e:
            print(f"{Fore.RED}‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: {str(e)}")
            return []

    def get_job_by_id(self, job_id: str) -> Optional[Dict[str, Any]]:
        """
        ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡πÇ‡∏î‡∏¢ ID
        
        Args:
            job_id: ID ‡∏Ç‡∏≠‡∏á‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
            
        Returns:
            ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏´‡∏£‡∏∑‡∏≠ None ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö
        """
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ metadata ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á
        if not self.job_metadata_path.exists():
            print(f"{Fore.RED}‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå metadata ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û")
            return None
        
        try:
            # ‡πÇ‡∏´‡∏•‡∏î metadata
            with open(self.job_metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            # ‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏à‡∏≤‡∏Å job_id
            for job in metadata["job_data"]:
                if job["id"] == job_id:
                    return job
            
            print(f"{Fore.YELLOW}‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ID: {job_id}")
            return None
            
        except Exception as e:
            print(f"{Fore.RED}‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û: {str(e)}")
            return None
    
    def get_advice_by_id(self, advice_id: str) -> Optional[Dict[str, Any]]:
        """
        ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡πÇ‡∏î‡∏¢ ID
        
        Args:
            advice_id: ID ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
            
        Returns:
            ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏´‡∏£‡∏∑‡∏≠ None ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö
        """
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ metadata ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á
        if not self.advice_metadata_path.exists():
            print(f"{Fore.RED}‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå metadata ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û")
            return None
        
        try:
            # ‡πÇ‡∏´‡∏•‡∏î metadata
            with open(self.advice_metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            # ‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏à‡∏≤‡∏Å advice_id
            for advice in metadata["advice_data"]:
                if advice["id"] == advice_id:
                    return advice
            
            print(f"{Fore.YELLOW}‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ID: {advice_id}")
            return None
            
        except Exception as e:
            print(f"{Fore.RED}‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: {str(e)}")
            return None


# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
if __name__ == "__main__":
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• SentenceTransformer (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
    model = None
    try:
        from sentence_transformers import SentenceTransformer
        print(f"{Fore.CYAN}üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• SentenceTransformer...")
        model = SentenceTransformer('intfloat/e5-small-v2')
        print(f"{Fore.GREEN}‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
    except Exception as e:
        print(f"{Fore.YELLOW}‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ: {str(e)}")
        print(f"{Fore.YELLOW}‚ö†Ô∏è ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡∏•‡∏≠‡∏á embedding ‡πÅ‡∏ó‡∏ô")
    
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏û‡∏≤‡∏ò‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå
    processed_data_dir = "data/processed"
    vector_db_dir = "data/vector_db"
    
    try:
        print(f"{Fore.CYAN}{'='*60}")
        print(f"{Fore.CYAN}= ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô VectorCreator")
        print(f"{Fore.CYAN}{'='*60}")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á VectorCreator
        creator = VectorCreator(
            processed_data_dir=processed_data_dir,
            vector_db_dir=vector_db_dir,
            embedding_model=model,
            clear_vector_db=True  # ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏°‡∏Å‡πà‡∏≠‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà
        )
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        results = creator.create_all_embeddings()
        
        # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
        print(f"\n{Fore.CYAN}{'='*60}")
        print(f"{Fore.CYAN}= ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤")
        print(f"{Fore.CYAN}{'='*60}")
        
        # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
        print(f"\n{Fore.CYAN}üîç ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö: '‡∏ô‡∏±‡∏Å‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏ã‡∏≠‡∏ü‡∏ï‡πå‡πÅ‡∏ß‡∏£‡πå'{Style.RESET_ALL}")
        creator.search_similar_jobs("‡∏ô‡∏±‡∏Å‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏ã‡∏≠‡∏ü‡∏ï‡πå‡πÅ‡∏ß‡∏£‡πå", k=3)
        
        print(f"\n{Fore.CYAN}üîç ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö: '‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£'{Style.RESET_ALL}")
        creator.search_similar_jobs("‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£", k=3)
        
        # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
        print(f"\n{Fore.CYAN}üîç ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö: '‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô resume'{Style.RESET_ALL}")
        creator.search_relevant_advices("‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô resume", k=3)
        
        print(f"\n{Fore.CYAN}üîç ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö: '‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ï‡∏±‡∏ß‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå‡∏á‡∏≤‡∏ô'{Style.RESET_ALL}")
        creator.search_relevant_advices("‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ï‡∏±‡∏ß‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå‡∏á‡∏≤‡∏ô", k=3)
        
        print(f"\n{Fore.GREEN}‚úÖ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
        
    except Exception as e:
        print(f"{Fore.RED}‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö: {str(e)}")


    def create_combined_embeddings(self) -> Dict[str, Any]:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡πÅ‡∏ö‡∏ö‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
        
        Returns:
            ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings
        """
        result = {
            "success": False,
            "vectors_count": 0,
            "error": None
        }
        
        try:
            # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
            job_data = self._load_job_data()
            
            # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
            advice_data = self._load_career_advice_data()
            
            # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ (‡∏à‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ)
            user_data = self._load_user_data()
            
            if not job_data and not advice_data:
                result["error"] = "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥"
                return result
            
            print(f"{Fore.CYAN}üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡πÅ‡∏ö‡∏ö‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡∏≠‡∏≤‡∏ä‡∏µ‡∏û {len(job_data)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£, ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ {len(advice_data)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£, ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ {len(user_data)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)...{Style.RESET_ALL}")
            
            # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings
            combined_texts = []
            combined_ids = []
            combined_data = []
            combined_types = []  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó ("job", "advice", "user")
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
            for job in job_data:
                if "id" not in job:
                    continue
                    
                job_text = self._prepare_text_for_embedding(job)
                job_id = f"job_{job['id']}"
                
                combined_texts.append(job_text)
                combined_ids.append(job_id)
                combined_data.append(job)
                combined_types.append("job")
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
            for advice in advice_data:
                if "id" not in advice:
                    continue
                    
                advice_text = self._prepare_advice_text_for_embedding(advice)
                advice_id = f"advice_{advice['id']}"
                
                combined_texts.append(advice_text)
                combined_ids.append(advice_id)
                combined_data.append(advice)
                combined_types.append("advice")
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
            for user in user_data:
                if "id" not in user:
                    continue
                    
                user_text = self._prepare_user_text_for_embedding(user)
                user_id = f"user_{user['id']}"
                
                combined_texts.append(user_text)
                combined_ids.append(user_id)
                combined_data.append(user)
                combined_types.append("user")
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            if not combined_texts:
                result["error"] = "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡πÑ‡∏î‡πâ"
                return result
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings
            print(f"{Fore.CYAN}üß† ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô {len(combined_texts)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£...{Style.RESET_ALL}")
            
            if self.embedding_model:
                # ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏£‡∏¥‡∏á
                embeddings = self.embedding_model.encode(combined_texts, show_progress_bar=True)
            else:
                # ‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡∏•‡∏≠‡∏á
                print(f"{Fore.YELLOW}‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• embedding ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡∏•‡∏≠‡∏á{Style.RESET_ALL}")
                embeddings = np.array([self._get_embedding(text) for text in combined_texts])
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á FAISS index
            print(f"{Fore.CYAN}üìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á FAISS index...{Style.RESET_ALL}")
            
            dimension = embeddings.shape[1]
            index = faiss.IndexFlatL2(dimension)
            index.add(embeddings.astype(np.float32))
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á mapping ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á id ‡∏Å‡∏±‡∏ö index
            combined_ids_to_index = {}
            for i, item_id in enumerate(combined_ids):
                combined_ids_to_index[item_id] = i
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏ß‡∏°
            combined_vector_dir = self.vector_db_dir / "combined_knowledge"
            combined_vector_dir.mkdir(parents=True, exist_ok=True)
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å FAISS index
            combined_index_path = combined_vector_dir / "faiss_index.bin"
            print(f"{Fore.CYAN}üíæ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å FAISS index ‡πÑ‡∏õ‡∏ó‡∏µ‡πà {combined_index_path}...{Style.RESET_ALL}")
            faiss.write_index(index, str(combined_index_path))
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å metadata
            combined_metadata_path = combined_vector_dir / "metadata.json"
            print(f"{Fore.CYAN}üíæ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å metadata ‡πÑ‡∏õ‡∏ó‡∏µ‡πà {combined_metadata_path}...{Style.RESET_ALL}")
            metadata = {
                "item_ids": combined_ids,
                "item_types": combined_types,
                "item_ids_to_index": combined_ids_to_index,
                "item_data": []
            }
            
            # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡∏•‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô metadata
            for i, item in enumerate(combined_data):
                item_type = combined_types[i]
                simplified_item = {"id": combined_ids[i], "type": item_type}
                
                if item_type == "job":
                    simplified_item.update({
                        "title": item.get("titles", [""])[0] if isinstance(item.get("titles"), list) else "",
                        "description": item.get("description", "")[:300] + "..." if len(item.get("description", "")) > 300 else item.get("description", ""),
                        "responsibilities": item.get("responsibilities", [])[:3],
                        "skills": item.get("skills", [])[:5],
                        "salary_ranges": item.get("salary_ranges", [])
                    })
                elif item_type == "advice":
                    simplified_item.update({
                        "title": item.get("title", ""),
                        "text_preview": item.get("text", "")[:300] + "..." if len(item.get("text", "")) > 300 else item.get("text", ""),
                        "tags": item.get("tags", []),
                        "source": item.get("source", ""),
                        "url": item.get("url", "")
                    })
                elif item_type == "user":
                    simplified_item.update({
                        "name": item.get("name", ""),
                        "institution": item.get("institution", ""),
                        "education_status": item.get("education_status", ""),
                        "skills": [skill.get("name") for skill in item.get("skills", [])][:5],
                        "programming_languages": item.get("programming_languages", [])[:5]
                    })
                
                metadata["item_data"].append(simplified_item)
            
            with open(combined_metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            print(f"{Fore.GREEN}‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡πÅ‡∏ö‡∏ö‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(combined_ids)} vectors{Style.RESET_ALL}")
            
            result["success"] = True
            result["vectors_count"] = len(combined_ids)
            
            return result
            
        except Exception as e:
            print(f"{Fore.RED}‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡πÅ‡∏ö‡∏ö‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {str(e)}{Style.RESET_ALL}")
            result["error"] = str(e)
            return result

    def _prepare_user_text_for_embedding(self, user: Dict[str, Any]) -> str:
        """
        ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á embedding
        
        Args:
            user: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
            
        Returns:
            ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á embedding
        """
        text_parts = []
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
        if "name" in user and user["name"]:
            text_parts.append(f"‡∏ä‡∏∑‡πà‡∏≠: {user['name']}")
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤
        if "institution" in user and user["institution"]:
            text_parts.append(f"‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤: {user['institution']}")
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤
        if "education_status" in user and user["education_status"]:
            status_mapping = {
                "student": "‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏®‡∏∂‡∏Å‡∏©‡∏≤",
                "graduate": "‡∏à‡∏ö‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤",
                "working": "‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß",
                "other": "‡∏≠‡∏∑‡πà‡∏ô‡πÜ"
            }
            status = status_mapping.get(user["education_status"], user["education_status"])
            text_parts.append(f"‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞: {status}")
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ä‡∏±‡πâ‡∏ô‡∏õ‡∏µ
        if "year" in user and user["year"]:
            text_parts.append(f"‡∏ä‡∏±‡πâ‡∏ô‡∏õ‡∏µ: {user['year']}")
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ó‡∏±‡∏Å‡∏©‡∏∞
        if "skills" in user and user["skills"]:
            skills_text = []
            for skill in user["skills"]:
                skill_name = skill.get("name", "")
                skill_level = skill.get("proficiency", 0)
                if skill_name:
                    skills_text.append(f"{skill_name} (‡∏£‡∏∞‡∏î‡∏±‡∏ö {skill_level}/5)")
            
            if skills_text:
                text_parts.append(f"‡∏ó‡∏±‡∏Å‡∏©‡∏∞: {', '.join(skills_text)}")
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°
        if "programming_languages" in user and user["programming_languages"]:
            text_parts.append(f"‡∏†‡∏≤‡∏©‡∏≤‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°: {', '.join(user['programming_languages'])}")
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠
        if "tools" in user and user["tools"]:
            text_parts.append(f"‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠: {', '.join(user['tools'])}")
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå
        if "projects" in user and user["projects"]:
            projects_text = []
            for project in user["projects"]:
                project_name = project.get("name", "")
                project_desc = project.get("description", "")
                project_tech = project.get("technologies", [])
                
                if project_name:
                    project_text = project_name
                    if project_desc:
                        project_text += f" - {project_desc}"
                    if project_tech:
                        project_text += f" (‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ: {', '.join(project_tech)})"
                    projects_text.append(project_text)
            
            if projects_text:
                text_parts.append(f"‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå: {'; '.join(projects_text)}")
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
        if "work_experiences" in user and user["work_experiences"]:
            work_text = []
            for work in user["work_experiences"]:
                work_title = work.get("title", "")
                work_company = work.get("company", "")
                work_start = work.get("start_date", "")
                work_end = work.get("end_date", "")
                work_desc = work.get("description", "")
                
                if work_title and work_company:
                    exp_text = f"{work_title} ‡∏ó‡∏µ‡πà {work_company}"
                    if work_start:
                        exp_text += f" ({work_start}"
                        if work_end:
                            exp_text += f" ‡∏ñ‡∏∂‡∏á {work_end}"
                        exp_text += ")"
                    if work_desc:
                        exp_text += f" - {work_desc}"
                    work_text.append(exp_text)
            
            if work_text:
                text_parts.append(f"‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå: {'; '.join(work_text)}")
        
        # ‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
        return " ".join(text_parts)

    def _load_user_data(self) -> List[Dict[str, Any]]:
        """
        ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå users.json
        
        Returns:
            List ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
        """
        try:
            from src.utils.config import USERS_DIR
            users_file = os.path.join(USERS_DIR, "users.json")
            
            if os.path.exists(users_file):
                with open(users_file, 'r', encoding='utf-8') as f:
                    users_data = json.load(f)
                    
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                    if isinstance(users_data, list):
                        print(f"{Fore.GREEN}‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(users_data)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£{Style.RESET_ALL}")
                        return users_data
                    else:
                        print(f"{Fore.YELLOW}‚ö†Ô∏è ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (List){Style.RESET_ALL}")
                        return []
            else:
                print(f"{Fore.YELLOW}‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ: {users_file}{Style.RESET_ALL}")
                return []
        except Exception as e:
            print(f"{Fore.RED}‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ: {str(e)}{Style.RESET_ALL}")
            return []

    def create_all_embeddings(self) -> Dict[str, Any]:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡∏ó‡∏±‡πâ‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
        
        Returns:
            ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings
        """
        print(f"{Fore.CYAN}{'='*60}")
        print(f"{Fore.CYAN}= ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Vector Database ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î")
        print(f"{Fore.CYAN}{'='*60}")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
        print(f"\n{Fore.CYAN}{'='*20} ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û {'='*20}")
        job_result = self.create_job_embeddings()
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
        print(f"\n{Fore.CYAN}{'='*20} ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û {'='*20}")
        advice_result = self.create_advice_embeddings()
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡πÅ‡∏ö‡∏ö‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        print(f"\n{Fore.CYAN}{'='*20} ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡πÅ‡∏ö‡∏ö‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {'='*20}")
        combined_result = self.create_combined_embeddings()
        
        return {
            "job_embeddings": job_result,
            "advice_embeddings": advice_result,
            "combined_embeddings": combined_result
        }