import os
import json
import shutil
import faiss
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
from sentence_transformers import SentenceTransformer
from colorama import init, Fore, Style

# ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô colorama
init(autoreset=True)

class VectorCreator:
    """
    ‡∏Ñ‡∏•‡∏≤‡∏™‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á vector embeddings ‡πÅ‡∏•‡∏∞‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• FAISS
    ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢ semantic search
    """
    def __init__(self, 
                processed_data_dir: str, 
                vector_db_dir: str,
                embedding_model=None,
                clear_vector_db: bool = True):
        """
        ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö VectorCreator
        
        Args:
            processed_data_dir: ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß
            vector_db_dir: ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏Å‡πá‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• vector
            embedding_model: ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á embedding ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡∏•‡∏≠‡∏á
            clear_vector_db: ‡∏•‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• vector ‡πÄ‡∏î‡∏¥‡∏°‡∏Å‡πà‡∏≠‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà
        """
        self.processed_data_dir = Path(processed_data_dir)
        self.vector_db_dir = Path(vector_db_dir)
        self.embedding_model = embedding_model
        
        # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏¢‡πà‡∏≠‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        self.job_vector_dir = self.vector_db_dir / "job_knowledge"
        self.advice_vector_dir = self.vector_db_dir / "career_advice"
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
        self.job_vector_dir.mkdir(parents=True, exist_ok=True)
        self.advice_vector_dir.mkdir(parents=True, exist_ok=True)
        
        # ‡πÑ‡∏ü‡∏•‡πå FAISS index ‡πÅ‡∏•‡∏∞ metadata
        self.job_index_path = self.job_vector_dir / "faiss_index.bin"
        self.job_metadata_path = self.job_vector_dir / "job_metadata.json"
        
        self.advice_index_path = self.advice_vector_dir / "faiss_index.bin"
        self.advice_metadata_path = self.advice_vector_dir / "metadata.json"
        
        # ‡∏•‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• vector ‡πÄ‡∏î‡∏¥‡∏°‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
        if clear_vector_db:
            self._clear_vector_database()
        
        print(f"{Fore.CYAN}VectorCreator ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
        print(f"{Fore.CYAN}üìÇ ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß: {self.processed_data_dir}")
        print(f"{Fore.CYAN}üìÇ ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• vector: {self.vector_db_dir}")
        print(f"{Fore.CYAN}ü§ñ ‡πÇ‡∏°‡πÄ‡∏î‡∏• Embedding: {type(self.embedding_model).__name__ if self.embedding_model else '‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏∞‡∏ö‡∏∏ (‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡∏•‡∏≠‡∏á)'}") 
    
    def _clear_vector_database(self) -> None:
        """‡∏•‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• vector ‡πÄ‡∏î‡∏¥‡∏°"""
        print(f"{Fore.YELLOW}‚ÑπÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏•‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• vector ‡πÄ‡∏î‡∏¥‡∏°...")
        
        # ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå FAISS index ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà
        if self.job_index_path.exists():
            os.remove(self.job_index_path)
            print(f"{Fore.GREEN}‚úÖ ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå {self.job_index_path} ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
        
        if self.job_metadata_path.exists():
            os.remove(self.job_metadata_path)
            print(f"{Fore.GREEN}‚úÖ ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå {self.job_metadata_path} ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
        
        if self.advice_index_path.exists():
            os.remove(self.advice_index_path)
            print(f"{Fore.GREEN}‚úÖ ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå {self.advice_index_path} ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
        
        if self.advice_metadata_path.exists():
            os.remove(self.advice_metadata_path)
            print(f"{Fore.GREEN}‚úÖ ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå {self.advice_metadata_path} ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
    
    def _create_mock_embedding(self, text: str, dimension: int = 384) -> np.ndarray:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á embedding ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÉ‡∏ô‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏• Embedding
        
        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á embedding
            dimension: ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á vector (default: 384 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö MiniLM)
            
        Returns:
            numpy array ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô embedding
        """
        # ‡πÉ‡∏ä‡πâ hash ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
        np.random.seed(hash(text) % 2**32)
        vector = np.random.random(dimension).astype(np.float32)
        # Normalize vector ‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö 1
        return vector / np.linalg.norm(vector)
    
    def _get_embedding(self, text: str, dimension: int = 384) -> np.ndarray:
        if self.embedding_model:
            # Ensure normalization
            embedding = self.embedding_model.encode(text)
            return embedding / np.linalg.norm(embedding)
        else:
            return self._create_mock_embedding(text, dimension)
    
    def _load_job_data(self) -> List[Dict[str, Any]]:
        """
        ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡πâ‡∏ß
        
        Returns:
            List ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
        """
        cleaned_jobs_dir = self.processed_data_dir / "cleaned_jobs"
        job_files = list(cleaned_jobs_dir.glob("*.json"))
        
        if not job_files:
            print(f"{Fore.RED}‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡πÉ‡∏ô {cleaned_jobs_dir}")
            return []
        
        print(f"{Fore.CYAN}üìö ‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û {len(job_files)} ‡πÑ‡∏ü‡∏•‡πå")
        
        job_data = []
        for file_path in job_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    job_data.append(data)
            except Exception as e:
                print(f"{Fore.RED}‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå {file_path}: {str(e)}")
        
        print(f"{Fore.GREEN}‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(job_data)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        return job_data
    
    def _load_career_advice_data(self) -> List[Dict[str, Any]]:
        """
        ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
        
        Returns:
            List ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
        """
        advice_file = self.processed_data_dir / "career_advices" / "career_advices.json"
        
        if not advice_file.exists():
            print(f"{Fore.RED}‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏ó‡∏µ‡πà {advice_file}")
            return []
        
        try:
            with open(advice_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
                if isinstance(data, dict) and "career_advices" in data:
                    advices = data["career_advices"]
                    print(f"{Fore.GREEN}‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(advices)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
                    return advices
                elif isinstance(data, list):
                    print(f"{Fore.GREEN}‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(data)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
                    return data
                else:
                    print(f"{Fore.RED}‚ùå ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
                    return []
        except Exception as e:
            print(f"{Fore.RED}‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå {advice_file}: {str(e)}")
            return []
    
    def _prepare_job_text_for_embedding(self, job: Dict[str, Any]) -> str:
        """
        ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á embedding
        
        Args:
            job: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
            
        Returns:
            ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á embedding
        """
        text_parts = []
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô
        if "titles" in job and job["titles"]:
            text_parts.append(f"‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô: {', '.join(job['titles'])}")
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢
        if "description" in job and job["description"]:
            text_parts.append(f"‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢: {job['description']}")
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏±‡∏ö‡∏ú‡∏¥‡∏î‡∏ä‡∏≠‡∏ö
        if "responsibilities" in job and job["responsibilities"]:
            resp_text = " ".join(f"- {resp}" for resp in job["responsibilities"])
            text_parts.append(f"‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏±‡∏ö‡∏ú‡∏¥‡∏î‡∏ä‡∏≠‡∏ö: {resp_text}")
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ó‡∏±‡∏Å‡∏©‡∏∞
        if "skills" in job and job["skills"]:
            skills_text = ", ".join(job["skills"])
            text_parts.append(f"‡∏ó‡∏±‡∏Å‡∏©‡∏∞: {skills_text}")
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå
        if "salary_ranges" in job and job["salary_ranges"]:
            salary_info = []
            for salary_range in job["salary_ranges"]:
                if "experience" in salary_range and "salary" in salary_range:
                    salary_info.append(f"‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå {salary_range['experience']} ‡∏õ‡∏µ: ‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô {salary_range['salary']} ‡∏ö‡∏≤‡∏ó")
            
            if salary_info:
                text_parts.append(f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô: {' '.join(salary_info)}")
        
        # ‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
        return " ".join(text_parts)
    
    def _prepare_advice_text_for_embedding(self, advice: Dict[str, Any]) -> str:
        text_parts = []
        
        # ‡πÄ‡∏ô‡πâ‡∏ô‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠
        if "title" in advice and advice["title"]:
            text_parts.append(f"‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠: {advice['title']} " * 3)
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤
        if "content" in advice and advice["content"]:
            text_parts.append(f"‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤: {advice['content']}")
        
        # ‡πÄ‡∏ô‡πâ‡∏ô‡πÅ‡∏ó‡πá‡∏Å
        if "tags" in advice and advice["tags"]:
            tags_text = ", ".join(advice["tags"])
            text_parts.append(f"‡πÅ‡∏ó‡πá‡∏Å: {tags_text} " * 2)
        
        return " ".join(text_parts)
    
    def create_job_embeddings(self) -> Dict[str, Any]:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡πÉ‡∏ô FAISS
        
        Returns:
            ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings
        """
        result = {
            "success": False,
            "vectors_count": 0,
            "error": None
        }
        
        try:
            # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
            job_data = self._load_job_data()
            
            if not job_data:
                result["error"] = "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û"
                return result
            
            print(f"{Fore.CYAN}üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û {len(job_data)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£...")
            
            # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings
            job_ids = []
            job_texts = []
            job_ids_to_index = {}
            
            for job in job_data:
                if "id" not in job:
                    continue
                
                job_text = self._prepare_job_text_for_embedding(job)
                job_texts.append(job_text)
                job_ids.append(job["id"])
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            if not job_texts:
                result["error"] = "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡πÑ‡∏î‡πâ"
                return result
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings
            print(f"{Fore.CYAN}üß† ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô {len(job_texts)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£...")
            
            if self.embedding_model:
                # ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏£‡∏¥‡∏á
                embeddings = self.embedding_model.encode(job_texts, show_progress_bar=True)
            else:
                # ‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡∏•‡∏≠‡∏á
                print(f"{Fore.YELLOW}‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• embedding ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡∏•‡∏≠‡∏á")
                embeddings = np.array([self._get_embedding(text) for text in job_texts])
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á FAISS index
            print(f"{Fore.CYAN}üìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á FAISS index...")
            
            dimension = embeddings.shape[1]
            index = faiss.IndexFlatL2(dimension)
            index.add(embeddings.astype(np.float32))
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á mapping ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á job_id ‡∏Å‡∏±‡∏ö index
            for i, job_id in enumerate(job_ids):
                job_ids_to_index[job_id] = i
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å FAISS index
            print(f"{Fore.CYAN}üíæ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å FAISS index ‡πÑ‡∏õ‡∏ó‡∏µ‡πà {self.job_index_path}...")
            faiss.write_index(index, str(self.job_index_path))
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å metadata
            print(f"{Fore.CYAN}üíæ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å metadata ‡πÑ‡∏õ‡∏ó‡∏µ‡πà {self.job_metadata_path}...")
            metadata = {
                "job_ids": job_ids,
                "job_ids_to_index": job_ids_to_index,
                "job_data": job_data
            }
            
            with open(self.job_metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            print(f"{Fore.GREEN}‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(job_ids)} vectors")
            
            result["success"] = True
            result["vectors_count"] = len(job_ids)
            
            return result
            
        except Exception as e:
            print(f"{Fore.RED}‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û: {str(e)}")
            result["error"] = str(e)
            return result
    
    def create_advice_embeddings(self) -> Dict[str, Any]:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡πÉ‡∏ô FAISS
        
        Returns:
            ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings
        """
        result = {
            "success": False,
            "vectors_count": 0,
            "error": None
        }
        
        try:
            # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
            advice_data = self._load_career_advice_data()
            
            if not advice_data:
                result["error"] = "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û"
                return result
            
            print(f"{Fore.CYAN}üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û {len(advice_data)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£...")
            
            # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings
            advice_ids = []
            advice_texts = []
            advice_ids_to_index = {}
            
            for i, advice in enumerate(advice_data):
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö ID
                if "id" not in advice:
                    advice["id"] = f"advice_{i}"
                
                advice_text = self._prepare_advice_text_for_embedding(advice)
                advice_texts.append(advice_text)
                advice_ids.append(advice["id"])
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            if not advice_texts:
                result["error"] = "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡πÑ‡∏î‡πâ"
                return result
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings
            print(f"{Fore.CYAN}üß† ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô {len(advice_texts)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£...")
            
            if self.embedding_model:
                # ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏£‡∏¥‡∏á
                embeddings = self.embedding_model.encode(advice_texts, show_progress_bar=True)
            else:
                # ‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡∏•‡∏≠‡∏á
                print(f"{Fore.YELLOW}‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• embedding ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡∏•‡∏≠‡∏á")
                embeddings = np.array([self._get_embedding(text) for text in advice_texts])
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á FAISS index
            print(f"{Fore.CYAN}üìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á FAISS index...")
            
            dimension = embeddings.shape[1]
            index = faiss.IndexFlatL2(dimension)
            index.add(embeddings.astype(np.float32))
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á mapping ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á advice_id ‡∏Å‡∏±‡∏ö index
            for i, advice_id in enumerate(advice_ids):
                advice_ids_to_index[advice_id] = i
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å FAISS index
            print(f"{Fore.CYAN}üíæ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å FAISS index ‡πÑ‡∏õ‡∏ó‡∏µ‡πà {self.advice_index_path}...")
            faiss.write_index(index, str(self.advice_index_path))
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å metadata
            print(f"{Fore.CYAN}üíæ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å metadata ‡πÑ‡∏õ‡∏ó‡∏µ‡πà {self.advice_metadata_path}...")
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• metadata ‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö
            simplified_advice_data = []
            for advice in advice_data:
                simplified = {
                    "id": advice["id"],
                    "title": advice.get("title", ""),
                    "tags": advice.get("tags", []),
                    "source": advice.get("source", ""),
                    "url": advice.get("url", "")
                }
                
                # ‡∏î‡∏∂‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
                if "content" in advice:
                    simplified["text"] = advice["content"][:500] + "..." if len(advice["content"]) > 500 else advice["content"]
                elif "paragraphs" in advice and advice["paragraphs"]:
                    joined_text = " ".join(advice["paragraphs"][:3])
                    simplified["text"] = joined_text[:500] + "..." if len(joined_text) > 500 else joined_text
                
                simplified_advice_data.append(simplified)
            
            metadata = {
                "advice_ids": advice_ids,
                "advice_ids_to_index": advice_ids_to_index,
                "advice_data": simplified_advice_data
            }
            
            with open(self.advice_metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            print(f"{Fore.GREEN}‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(advice_ids)} vectors")
            
            result["success"] = True
            result["vectors_count"] = len(advice_ids)
            
            return result
            
        except Exception as e:
            print(f"{Fore.RED}‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û: {str(e)}")
            result["error"] = str(e)
            return result
    
    def create_all_embeddings(self) -> Dict[str, Any]:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡∏ó‡∏±‡πâ‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
        
        Returns:
            ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings
        """
        print(f"{Fore.CYAN}{'='*60}")
        print(f"{Fore.CYAN}= ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Vector Database ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î")
        print(f"{Fore.CYAN}{'='*60}")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
        print(f"\n{Fore.CYAN}{'='*20} ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û {'='*20}")
        job_result = self.create_job_embeddings()
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
        print(f"\n{Fore.CYAN}{'='*20} ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û {'='*20}")
        advice_result = self.create_advice_embeddings()
        
        return {
            "job_embeddings": job_result,
            "advice_embeddings": advice_result
        }
    
    def search_similar_jobs(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """
        ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
        
        Args:
            query: ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
            k: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
            
        Returns:
            ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
        """
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ vector database ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á
        if not self.job_index_path.exists() or not self.job_metadata_path.exists():
            print(f"{Fore.RED}‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö vector database ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û")
            return []
        
        try:
            # ‡πÇ‡∏´‡∏•‡∏î FAISS index
            index = faiss.read_index(str(self.job_index_path))
            
            # ‡πÇ‡∏´‡∏•‡∏î metadata
            with open(self.job_metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á embedding ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
            query_embedding = None
            if self.embedding_model:
                query_embedding = self.embedding_model.encode([query])[0]
            else:
                query_embedding = self._get_embedding(query)
            
            # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÉ‡∏ô FAISS
            query_embedding = np.array([query_embedding]).astype(np.float32)
            distances, indices = index.search(query_embedding, k)
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            results = []
            for i, idx in enumerate(indices[0]):
                if idx == -1 or idx >= len(metadata["job_ids"]):
                    continue
                
                job_id = metadata["job_ids"][idx]
                job_data = None
                
                # ‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏à‡∏≤‡∏Å job_id
                for job in metadata["job_data"]:
                    if job["id"] == job_id:
                        job_data = job
                        break
                
                if job_data is None:
                    continue
                
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á (1 - ‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á)
                similarity = 1.0 / (1.0 + distances[0][i])
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                result = {
                    "id": job_id,
                    "title": job_data["titles"][0] if job_data["titles"] else job_id,
                    "similarity": similarity,
                    "description": job_data.get("description", ""),
                    "responsibilities": job_data.get("responsibilities", []),
                    "skills": job_data.get("skills", []),
                }
                
                results.append(result)
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
                print(f"{i+1}. {Fore.GREEN}{result['title']}{Style.RESET_ALL} " + 
                     f"(‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô: {Fore.YELLOW}{result['similarity']:.2f}{Style.RESET_ALL})")
            
            return results
        
        except Exception as e:
            print(f"{Fore.RED}‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏≠‡∏≤‡∏ä‡∏µ‡∏û: {str(e)}")
            return []
    
    def search_relevant_advices(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """
        ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
        
        Args:
            query: ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
            k: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
            
        Returns:
            ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
        """
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ vector database ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á
        if not self.advice_index_path.exists() or not self.advice_metadata_path.exists():
            print(f"{Fore.RED}‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö vector database ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û")
            return []
        
        try:
            # ‡πÇ‡∏´‡∏•‡∏î FAISS index
            index = faiss.read_index(str(self.advice_index_path))
            
            # ‡πÇ‡∏´‡∏•‡∏î metadata
            with open(self.advice_metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á embedding ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
            query_embedding = None
            if self.embedding_model:
                query_embedding = self.embedding_model.encode([query])[0]
            else:
                query_embedding = self._get_embedding(query)
            
            # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÉ‡∏ô FAISS
            query_embedding = np.array([query_embedding]).astype(np.float32)
            distances, indices = index.search(query_embedding, k)
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            results = []
            for i, idx in enumerate(indices[0]):
                if idx == -1 or idx >= len(metadata["advice_ids"]):
                    continue
                
                advice_id = metadata["advice_ids"][idx]
                advice_data = None
                
                # ‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏à‡∏≤‡∏Å advice_id
                for advice in metadata["advice_data"]:
                    if advice["id"] == advice_id:
                        advice_data = advice
                        break
                
                if advice_data is None:
                    continue
                
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á (1 - ‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á)
                similarity = 1.0 / (1.0 + distances[0][i])
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                result = {
                    "id": advice_id,
                    "title": advice_data.get("title", ""),
                    "similarity": similarity,
                    "text": advice_data.get("text", ""),
                    "tags": advice_data.get("tags", []),
                    "source": advice_data.get("source", ""),
                    "url": advice_data.get("url", "")
                }
                
                results.append(result)
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
                tags_str = f", ‡πÅ‡∏ó‡πá‡∏Å: {', '.join(result['tags'])}" if result['tags'] else ""
                print(f"{i+1}. {Fore.GREEN}{result['title']}{Style.RESET_ALL} " + 
                    f"(‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô: {Fore.YELLOW}{result['similarity']:.2f}{Style.RESET_ALL}{tags_str})")
            
            return results
        
        except Exception as e:
            print(f"{Fore.RED}‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: {str(e)}")
            return []

    def get_job_by_id(self, job_id: str) -> Optional[Dict[str, Any]]:
        """
        ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡πÇ‡∏î‡∏¢ ID
        
        Args:
            job_id: ID ‡∏Ç‡∏≠‡∏á‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
            
        Returns:
            ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏´‡∏£‡∏∑‡∏≠ None ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö
        """
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ metadata ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á
        if not self.job_metadata_path.exists():
            print(f"{Fore.RED}‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå metadata ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û")
            return None
        
        try:
            # ‡πÇ‡∏´‡∏•‡∏î metadata
            with open(self.job_metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            # ‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏à‡∏≤‡∏Å job_id
            for job in metadata["job_data"]:
                if job["id"] == job_id:
                    return job
            
            print(f"{Fore.YELLOW}‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ID: {job_id}")
            return None
            
        except Exception as e:
            print(f"{Fore.RED}‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏ä‡∏µ‡∏û: {str(e)}")
            return None
    
    def get_advice_by_id(self, advice_id: str) -> Optional[Dict[str, Any]]:
        """
        ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡πÇ‡∏î‡∏¢ ID
        
        Args:
            advice_id: ID ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
            
        Returns:
            ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏´‡∏£‡∏∑‡∏≠ None ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö
        """
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ metadata ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á
        if not self.advice_metadata_path.exists():
            print(f"{Fore.RED}‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå metadata ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û")
            return None
        
        try:
            # ‡πÇ‡∏´‡∏•‡∏î metadata
            with open(self.advice_metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            # ‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏à‡∏≤‡∏Å advice_id
            for advice in metadata["advice_data"]:
                if advice["id"] == advice_id:
                    return advice
            
            print(f"{Fore.YELLOW}‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ID: {advice_id}")
            return None
            
        except Exception as e:
            print(f"{Fore.RED}‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: {str(e)}")
            return None


# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
if __name__ == "__main__":
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• SentenceTransformer (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
    model = None
    try:
        from sentence_transformers import SentenceTransformer
        print(f"{Fore.CYAN}üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• SentenceTransformer...")
        model = SentenceTransformer('intfloat/multilingual-e5-large')
        print(f"{Fore.GREEN}‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
    except Exception as e:
        print(f"{Fore.YELLOW}‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ: {str(e)}")
        print(f"{Fore.YELLOW}‚ö†Ô∏è ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡∏•‡∏≠‡∏á embedding ‡πÅ‡∏ó‡∏ô")
    
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏û‡∏≤‡∏ò‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå
    processed_data_dir = "data/processed"
    vector_db_dir = "data/vector_db"
    
    try:
        print(f"{Fore.CYAN}{'='*60}")
        print(f"{Fore.CYAN}= ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô VectorCreator")
        print(f"{Fore.CYAN}{'='*60}")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á VectorCreator
        creator = VectorCreator(
            processed_data_dir=processed_data_dir,
            vector_db_dir=vector_db_dir,
            embedding_model=model,
            clear_vector_db=True  # ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏°‡∏Å‡πà‡∏≠‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà
        )
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        results = creator.create_all_embeddings()
        
        # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
        print(f"\n{Fore.CYAN}{'='*60}")
        print(f"{Fore.CYAN}= ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤")
        print(f"{Fore.CYAN}{'='*60}")
        
        # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
        print(f"\n{Fore.CYAN}üîç ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö: '‡∏ô‡∏±‡∏Å‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏ã‡∏≠‡∏ü‡∏ï‡πå‡πÅ‡∏ß‡∏£‡πå'{Style.RESET_ALL}")
        creator.search_similar_jobs("‡∏ô‡∏±‡∏Å‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏ã‡∏≠‡∏ü‡∏ï‡πå‡πÅ‡∏ß‡∏£‡πå", k=3)
        
        print(f"\n{Fore.CYAN}üîç ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö: '‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£'{Style.RESET_ALL}")
        creator.search_similar_jobs("‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£", k=3)
        
        # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
        print(f"\n{Fore.CYAN}üîç ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö: '‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô resume'{Style.RESET_ALL}")
        creator.search_relevant_advices("‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô resume", k=3)
        
        print(f"\n{Fore.CYAN}üîç ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö: '‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ï‡∏±‡∏ß‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå‡∏á‡∏≤‡∏ô'{Style.RESET_ALL}")
        creator.search_relevant_advices("‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ï‡∏±‡∏ß‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå‡∏á‡∏≤‡∏ô", k=3)
        
        print(f"\n{Fore.GREEN}‚úÖ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
        
    except Exception as e:
        print(f"{Fore.RED}‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö: {str(e)}")