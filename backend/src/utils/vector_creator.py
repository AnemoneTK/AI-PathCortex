# backend/src/utils/vector_creator.py
import os
import json
import shutil
import faiss
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
from sentence_transformers import SentenceTransformer
from colorama import init, Fore, Style

# р╣Ар╕гр╕┤р╣Ир╕бр╕Хр╣Йр╕Щр╣Гр╕Кр╣Йр╕Зр╕▓р╕Щ colorama
init(autoreset=True)

class VectorCreator:
    """
    р╕Др╕ер╕▓р╕кр╕кр╕│р╕лр╕гр╕▒р╕Ър╕кр╕гр╣Йр╕▓р╕З vector embeddings р╣Бр╕ер╕░р╕Рр╕▓р╕Щр╕Вр╣Йр╕нр╕бр╕╣р╕е FAISS
    р╕кр╕│р╕лр╕гр╕▒р╕Ър╕Бр╕▓р╕гр╕Др╣Йр╕Щр╕лр╕▓р╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Фр╣Йр╕зр╕в semantic search
    """
    def __init__(self, 
                processed_data_dir: str, 
                vector_db_dir: str,
                embedding_model=None,
                clear_vector_db: bool = True):
        """
        р╕Бр╕│р╕лр╕Щр╕Фр╕Др╣Ир╕▓р╣Ар╕гр╕┤р╣Ир╕бр╕Хр╣Йр╕Щр╕кр╕│р╕лр╕гр╕▒р╕Ъ VectorCreator
        
        Args:
            processed_data_dir: р╣Вр╕Яр╕ер╣Ар╕Фр╕нр╕гр╣Мр╕Чр╕╡р╣Ир╣Ар╕Бр╣Зр╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Чр╕╡р╣Ир╕Ьр╣Ир╕▓р╕Щр╕Бр╕▓р╕гр╕Ыр╕гр╕░р╕бр╕зр╕ер╕Ьр╕ер╣Бр╕ер╣Йр╕з
            vector_db_dir: р╣Вр╕Яр╕ер╣Ар╕Фр╕нр╕гр╣Мр╕Чр╕╡р╣Ир╕Ир╕░р╣Ар╕Бр╣Зр╕Ър╕Рр╕▓р╕Щр╕Вр╣Йр╕нр╕бр╕╣р╕е vector
            embedding_model: р╣Вр╕бр╣Ар╕Фр╕ер╕кр╕│р╕лр╕гр╕▒р╕Ър╕кр╕гр╣Йр╕▓р╕З embedding р╕лр╕▓р╕Бр╣Др╕бр╣Ир╕гр╕░р╕Ър╕╕р╕Ир╕░р╣Гр╕Кр╣Йр╕Бр╕▓р╕гр╕Ир╕│р╕ер╕нр╕З
            clear_vector_db: р╕ер╣Йр╕▓р╕Зр╕Рр╕▓р╕Щр╕Вр╣Йр╕нр╕бр╕╣р╕е vector р╣Ар╕Фр╕┤р╕бр╕Бр╣Ир╕нр╕Щр╕кр╕гр╣Йр╕▓р╕Зр╣Гр╕лр╕бр╣И
        """
        self.processed_data_dir = Path(processed_data_dir)
        self.vector_db_dir = Path(vector_db_dir)
        self.embedding_model = embedding_model
        
        # р╣Вр╕Яр╕ер╣Ар╕Фр╕нр╕гр╣Мр╕вр╣Ир╕нр╕вр╕кр╕│р╕лр╕гр╕▒р╕Ър╣Бр╕Хр╣Ир╕ер╕░р╕Ыр╕гр╕░р╣Ар╕ар╕Чр╕Вр╕нр╕Зр╕Вр╣Йр╕нр╕бр╕╣р╕е
        self.job_vector_dir = self.vector_db_dir / "job_knowledge"
        self.advice_vector_dir = self.vector_db_dir / "career_advice"
        
        # р╕кр╕гр╣Йр╕▓р╕Зр╣Вр╕Яр╕ер╣Ар╕Фр╕нр╕гр╣Мр╕Цр╣Йр╕▓р╕вр╕▒р╕Зр╣Др╕бр╣Ир╕бр╕╡
        self.job_vector_dir.mkdir(parents=True, exist_ok=True)
        self.advice_vector_dir.mkdir(parents=True, exist_ok=True)
        
        # р╣Др╕Яр╕ер╣М FAISS index р╣Бр╕ер╕░ metadata
        self.job_index_path = self.job_vector_dir / "faiss_index.bin"
        self.job_metadata_path = self.job_vector_dir / "metadata.json"
        
        self.advice_index_path = self.advice_vector_dir / "faiss_index.bin"
        self.advice_metadata_path = self.advice_vector_dir / "metadata.json"
        
        # р╕ер╣Йр╕▓р╕Зр╕Рр╕▓р╕Щр╕Вр╣Йр╕нр╕бр╕╣р╕е vector р╣Ар╕Фр╕┤р╕бр╕Цр╣Йр╕▓р╕Ир╕│р╣Ар╕Ыр╣Зр╕Щ
        if clear_vector_db:
            self._clear_vector_database()
        
        print(f"{Fore.CYAN}VectorCreator р╣Ар╕гр╕┤р╣Ир╕бр╕Хр╣Йр╕Щр╣Ар╕гр╕╡р╕вр╕Ър╕гр╣Йр╕нр╕в")
        print(f"{Fore.CYAN}ЁЯУВ р╣Вр╕Яр╕ер╣Ар╕Фр╕нр╕гр╣Мр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Чр╕╡р╣Ир╕Ыр╕гр╕░р╕бр╕зр╕ер╕Ьр╕ер╣Бр╕ер╣Йр╕з: {self.processed_data_dir}")
        print(f"{Fore.CYAN}ЁЯУВ р╣Вр╕Яр╕ер╣Ар╕Фр╕нр╕гр╣Мр╕кр╕│р╕лр╕гр╕▒р╕Ър╣Ар╕Бр╣Зр╕Ър╕Рр╕▓р╕Щр╕Вр╣Йр╕нр╕бр╕╣р╕е vector: {self.vector_db_dir}")
        print(f"{Fore.CYAN}ЁЯдЦ р╣Вр╕бр╣Ар╕Фр╕е Embedding: {type(self.embedding_model).__name__ if self.embedding_model else 'р╣Др╕бр╣Ир╣Др╕Фр╣Йр╕гр╕░р╕Ър╕╕ (р╕Ир╕░р╣Гр╕Кр╣Йр╕Бр╕▓р╕гр╕Ир╕│р╕ер╕нр╕З)'}") 
    
    def _clear_vector_database(self) -> None:
        """р╕ер╣Йр╕▓р╕Зр╕Рр╕▓р╕Щр╕Вр╣Йр╕нр╕бр╕╣р╕е vector р╣Ар╕Фр╕┤р╕б"""
        print(f"{Fore.YELLOW}тД╣я╕П р╕Бр╕│р╕ер╕▒р╕Зр╕ер╣Йр╕▓р╕Зр╕Рр╕▓р╕Щр╕Вр╣Йр╕нр╕бр╕╣р╕е vector р╣Ар╕Фр╕┤р╕б...")
        
        # р╕ер╕Ър╣Др╕Яр╕ер╣М FAISS index р╕Цр╣Йр╕▓р╕бр╕╡р╕нр╕вр╕╣р╣И
        if self.job_index_path.exists():
            os.remove(self.job_index_path)
            print(f"{Fore.GREEN}тЬЕ р╕ер╕Ър╣Др╕Яр╕ер╣М {self.job_index_path} р╣Ар╕гр╕╡р╕вр╕Ър╕гр╣Йр╕нр╕в")
        
        if self.job_metadata_path.exists():
            os.remove(self.job_metadata_path)
            print(f"{Fore.GREEN}тЬЕ р╕ер╕Ър╣Др╕Яр╕ер╣М {self.job_metadata_path} р╣Ар╕гр╕╡р╕вр╕Ър╕гр╣Йр╕нр╕в")
        
        if self.advice_index_path.exists():
            os.remove(self.advice_index_path)
            print(f"{Fore.GREEN}тЬЕ р╕ер╕Ър╣Др╕Яр╕ер╣М {self.advice_index_path} р╣Ар╕гр╕╡р╕вр╕Ър╕гр╣Йр╕нр╕в")
        
        if self.advice_metadata_path.exists():
            os.remove(self.advice_metadata_path)
            print(f"{Fore.GREEN}тЬЕ р╕ер╕Ър╣Др╕Яр╕ер╣М {self.advice_metadata_path} р╣Ар╕гр╕╡р╕вр╕Ър╕гр╣Йр╕нр╕в")
    
    def _create_mock_embedding(self, text: str, dimension: int = 384) -> np.ndarray:
        """
        р╕кр╕гр╣Йр╕▓р╕З embedding р╕Ир╕│р╕ер╕нр╕Зр╣Гр╕Щр╕Бр╕гр╕Ур╕╡р╕Чр╕╡р╣Ир╣Др╕бр╣Ир╕бр╕╡р╣Вр╕бр╣Ар╕Фр╕е Embedding
        
        Args:
            text: р╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╕Чр╕╡р╣Ир╕Хр╣Йр╕нр╕Зр╕Бр╕▓р╕гр╕кр╕гр╣Йр╕▓р╕З embedding
            dimension: р╕Вр╕Щр╕▓р╕Фр╕Вр╕нр╕З vector (default: 384 р╕кр╕│р╕лр╕гр╕▒р╕Ъ MiniLM)
            
        Returns:
            numpy array р╕Чр╕╡р╣Ир╣Ар╕Ыр╣Зр╕Щ embedding
        """
        # р╣Гр╕Кр╣Й hash р╕Вр╕нр╕Зр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╣Ар╕Юр╕╖р╣Ир╕нр╣Гр╕лр╣Йр╣Др╕Фр╣Йр╕Др╣Ир╕▓р╣Ар╕Фр╕┤р╕бр╣Ар╕бр╕╖р╣Ир╕нр╣Гр╕лр╣Йр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╣Ар╕Фр╕╡р╕вр╕зр╕Бр╕▒р╕Щ
        np.random.seed(hash(text) % 2**32)
        vector = np.random.random(dimension).astype(np.float32)
        # Normalize vector р╣Гр╕лр╣Йр╕бр╕╡р╕Др╕зр╕▓р╕бр╕вр╕▓р╕зр╣Ар╕Чр╣Ир╕▓р╕Бр╕▒р╕Ъ 1
        return vector / np.linalg.norm(vector)
    
    def _get_embedding(self, text: str, dimension: int = 384) -> np.ndarray:
        if self.embedding_model:
            # Ensure normalization
            embedding = self.embedding_model.encode(text)
            return embedding / np.linalg.norm(embedding)
        else:
            return self._create_mock_embedding(text, dimension)
    
    def _load_job_data(self) -> List[Dict[str, Any]]:
        """
        р╣Вр╕лр╕ер╕Фр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Юр╕Ир╕▓р╕Бр╣Др╕Яр╕ер╣Мр╕Чр╕╡р╣Ир╕Чр╕│р╕Др╕зр╕▓р╕бр╕кр╕░р╕нр╕▓р╕Фр╣Бр╕ер╣Йр╕з
        
        Returns:
            List р╕Вр╕нр╕Зр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Ю
        """
        cleaned_jobs_dir = self.processed_data_dir / "cleaned_jobs"
        job_files = list(cleaned_jobs_dir.glob("*.json"))
        
        if not job_files:
            print(f"{Fore.RED}тЭМ р╣Др╕бр╣Ир╕Юр╕Ър╣Др╕Яр╕ер╣Мр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Юр╣Гр╕Щ {cleaned_jobs_dir}")
            return []
        
        print(f"{Fore.CYAN}ЁЯУЪ р╕Юр╕Ър╣Др╕Яр╕ер╣Мр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Ю {len(job_files)} р╣Др╕Яр╕ер╣М")
        
        job_data = []
        for file_path in job_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    job_data.append(data)
            except Exception as e:
                print(f"{Fore.RED}тЭМ р╣Ар╕Бр╕┤р╕Фр╕Вр╣Йр╕нр╕Ьр╕┤р╕Фр╕Юр╕ер╕▓р╕Фр╣Гр╕Щр╕Бр╕▓р╕гр╕нр╣Ир╕▓р╕Щр╣Др╕Яр╕ер╣М {file_path}: {str(e)}")
        
        print(f"{Fore.GREEN}тЬЕ р╣Вр╕лр╕ер╕Фр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Юр╕кр╕│р╣Ар╕гр╣Зр╕И: {len(job_data)} р╕гр╕▓р╕вр╕Бр╕▓р╕г")
        return job_data
    
    def _load_career_advice_data(self) -> List[Dict[str, Any]]:
        """
        р╣Вр╕лр╕ер╕Фр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕нр╕▓р╕Кр╕╡р╕Ю
        
        Returns:
            List р╕Вр╕нр╕Зр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕нр╕▓р╕Кр╕╡р╕Ю
        """
        advice_file = self.processed_data_dir / "career_advices" / "career_advices.json"
        
        if not advice_file.exists():
            print(f"{Fore.RED}тЭМ р╣Др╕бр╣Ир╕Юр╕Ър╣Др╕Яр╕ер╣Мр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕нр╕▓р╕Кр╕╡р╕Юр╕Чр╕╡р╣И {advice_file}")
            return []
        
        try:
            with open(advice_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
                if isinstance(data, dict) and "career_advices" in data:
                    advices = data["career_advices"]
                    print(f"{Fore.GREEN}тЬЕ р╣Вр╕лр╕ер╕Фр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕нр╕▓р╕Кр╕╡р╕Юр╕кр╕│р╣Ар╕гр╣Зр╕И: {len(advices)} р╕гр╕▓р╕вр╕Бр╕▓р╕г")
                    return advices
                elif isinstance(data, list):
                    print(f"{Fore.GREEN}тЬЕ р╣Вр╕лр╕ер╕Фр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕нр╕▓р╕Кр╕╡р╕Юр╕кр╕│р╣Ар╕гр╣Зр╕И: {len(data)} р╕гр╕▓р╕вр╕Бр╕▓р╕г")
                    return data
                else:
                    print(f"{Fore.RED}тЭМ р╕гр╕╣р╕Ыр╣Бр╕Ър╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕нр╕▓р╕Кр╕╡р╕Юр╣Др╕бр╣Ир╕Цр╕╣р╕Бр╕Хр╣Йр╕нр╕З")
                    return []
        except Exception as e:
            print(f"{Fore.RED}тЭМ р╣Ар╕Бр╕┤р╕Фр╕Вр╣Йр╕нр╕Ьр╕┤р╕Фр╕Юр╕ер╕▓р╕Фр╣Гр╕Щр╕Бр╕▓р╕гр╕нр╣Ир╕▓р╕Щр╣Др╕Яр╕ер╣М {advice_file}: {str(e)}")
            return []
    
    def _prepare_job_text_for_embedding(self, job: Dict[str, Any]) -> str:
        """
        р╣Ар╕Хр╕гр╕╡р╕вр╕бр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╕Ир╕▓р╕Бр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Юр╕кр╕│р╕лр╕гр╕▒р╕Ър╕кр╕гр╣Йр╕▓р╕З embedding
        
        Args:
            job: р╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Ю
            
        Returns:
            р╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╕Чр╕╡р╣Ир╕Юр╕гр╣Йр╕нр╕бр╕кр╕│р╕лр╕гр╕▒р╕Ър╕кр╕гр╣Йр╕▓р╕З embedding
        """
        text_parts = []
        
        # р╣Ар╕Юр╕┤р╣Ир╕бр╕Кр╕╖р╣Ир╕нр╕Хр╕│р╣Бр╕лр╕Щр╣Ир╕Зр╕Зр╕▓р╕Щ
        if "titles" in job and job["titles"]:
            text_parts.append(f"р╕Хр╕│р╣Бр╕лр╕Щр╣Ир╕Зр╕Зр╕▓р╕Щ: {', '.join(job['titles'])}")
        
        # р╣Ар╕Юр╕┤р╣Ир╕бр╕Др╕│р╕нр╕Шр╕┤р╕Ър╕▓р╕в
        if "description" in job and job["description"]:
            text_parts.append(f"р╕Др╕│р╕нр╕Шр╕┤р╕Ър╕▓р╕в: {job['description']}")
        
        # р╣Ар╕Юр╕┤р╣Ир╕бр╕Др╕зр╕▓р╕бр╕гр╕▒р╕Ър╕Ьр╕┤р╕Фр╕Кр╕нр╕Ъ
        if "responsibilities" in job and job["responsibilities"]:
            resp_text = " ".join(f"- {resp}" for resp in job["responsibilities"])
            text_parts.append(f"р╕Др╕зр╕▓р╕бр╕гр╕▒р╕Ър╕Ьр╕┤р╕Фр╕Кр╕нр╕Ъ: {resp_text}")
        
        # р╣Ар╕Юр╕┤р╣Ир╕бр╕Чр╕▒р╕Бр╕йр╕░
        if "skills" in job and job["skills"]:
            skills_text = ", ".join(job["skills"])
            text_parts.append(f"р╕Чр╕▒р╕Бр╕йр╕░: {skills_text}")
        
        # р╣Ар╕Юр╕┤р╣Ир╕бр╕гр╕░р╕Фр╕▒р╕Ър╣Ар╕Зр╕┤р╕Щр╣Ар╕Фр╕╖р╕нр╕Щр╣Бр╕ер╕░р╕Ыр╕гр╕░р╕кр╕Ър╕Бр╕▓р╕гр╕Ур╣М
        if "salary_ranges" in job and job["salary_ranges"]:
            salary_info = []
            for salary_range in job["salary_ranges"]:
                if "experience" in salary_range and "salary" in salary_range:
                    salary_info.append(f"р╕Ыр╕гр╕░р╕кр╕Ър╕Бр╕▓р╕гр╕Ур╣М {salary_range['experience']} р╕Ыр╕╡: р╣Ар╕Зр╕┤р╕Щр╣Ар╕Фр╕╖р╕нр╕Щ {salary_range['salary']} р╕Ър╕▓р╕Ч")
            
            if salary_info:
                text_parts.append(f"р╕Вр╣Йр╕нр╕бр╕╣р╕ер╣Ар╕Зр╕┤р╕Щр╣Ар╕Фр╕╖р╕нр╕Щ: {' '.join(salary_info)}")
        
        # р╕гр╕зр╕бр╕Чр╕╕р╕Бр╕кр╣Ир╕зр╕Щр╣Ар╕Вр╣Йр╕▓р╕Фр╣Йр╕зр╕вр╕Бр╕▒р╕Щ
        return " ".join(text_parts)
    
    def _prepare_advice_text_for_embedding(self, advice: Dict[str, Any]) -> str:
        text_parts = []
        
        # р╣Ар╕Щр╣Йр╕Щр╕лр╕▒р╕зр╕Вр╣Йр╕н
        if "title" in advice and advice["title"]:
            text_parts.append(f"р╕лр╕▒р╕зр╕Вр╣Йр╕н: {advice['title']} " * 3)
        
        # р╣Ар╕Юр╕┤р╣Ир╕бр╣Ар╕Щр╕╖р╣Йр╕нр╕лр╕▓
        if "content" in advice and advice["content"]:
            text_parts.append(f"р╣Ар╕Щр╕╖р╣Йр╕нр╕лр╕▓: {advice['content']}")
        
        # р╣Ар╕Щр╣Йр╕Щр╣Бр╕Чр╣Зр╕Б
        if "tags" in advice and advice["tags"]:
            tags_text = ", ".join(advice["tags"])
            text_parts.append(f"р╣Бр╕Чр╣Зр╕Б: {tags_text} " * 2)
        
        return " ".join(text_parts)
    
    def create_job_embeddings(self) -> Dict[str, Any]:
        """
        р╕кр╕гр╣Йр╕▓р╕З embeddings р╕кр╕│р╕лр╕гр╕▒р╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Юр╣Бр╕ер╕░р╕Ър╕▒р╕Щр╕Чр╕╢р╕Бр╕ер╕Зр╣Гр╕Щ FAISS
        
        Returns:
            р╕Ьр╕ер╕ер╕▒р╕Юр╕Шр╣Мр╕Вр╕нр╕Зр╕Бр╕▓р╕гр╕кр╕гр╣Йр╕▓р╕З embeddings
        """
        result = {
            "success": False,
            "vectors_count": 0,
            "error": None
        }
        
        try:
            # р╣Вр╕лр╕ер╕Фр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Ю
            job_data = self._load_job_data()
            
            if not job_data:
                result["error"] = "р╣Др╕бр╣Ир╕Юр╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Ю"
                return result
            
            print(f"{Fore.CYAN}ЁЯФД р╕Бр╕│р╕ер╕▒р╕Зр╕кр╕гр╣Йр╕▓р╕З embeddings р╕кр╕│р╕лр╕гр╕▒р╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Ю {len(job_data)} р╕гр╕▓р╕вр╕Бр╕▓р╕г...")
            
            # р╣Ар╕Хр╕гр╕╡р╕вр╕бр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕кр╕│р╕лр╕гр╕▒р╕Ър╕кр╕гр╣Йр╕▓р╕З embeddings
            job_ids = []
            job_texts = []
            job_ids_to_index = {}
            
            for job in job_data:
                if "id" not in job:
                    continue
                
                job_text = self._prepare_job_text_for_embedding(job)
                job_texts.append(job_text)
                job_ids.append(job["id"])
            
            # р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕е
            if not job_texts:
                result["error"] = "р╣Др╕бр╣Ир╕кр╕▓р╕бр╕▓р╕гр╕Цр╣Ар╕Хр╕гр╕╡р╕вр╕бр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╕кр╕│р╕лр╕гр╕▒р╕Ър╕кр╕гр╣Йр╕▓р╕З embeddings р╣Др╕Фр╣Й"
                return result
            
            # р╕кр╕гр╣Йр╕▓р╕З embeddings
            print(f"{Fore.CYAN}ЁЯза р╕Бр╕│р╕ер╕▒р╕Зр╕кр╕гр╣Йр╕▓р╕З embeddings р╕Ир╕│р╕Щр╕зр╕Щ {len(job_texts)} р╕гр╕▓р╕вр╕Бр╕▓р╕г...")
            
            if self.embedding_model:
                # р╣Гр╕Кр╣Йр╣Вр╕бр╣Ар╕Фр╕ер╕Ир╕гр╕┤р╕З
                embeddings = self.embedding_model.encode(job_texts, show_progress_bar=True)
            else:
                # р╣Гр╕Кр╣Йр╕Бр╕▓р╕гр╕Ир╕│р╕ер╕нр╕З
                print(f"{Fore.YELLOW}тЪая╕П р╣Др╕бр╣Ир╕Юр╕Ър╣Вр╕бр╣Ар╕Фр╕е embedding р╕Ир╕░р╣Гр╕Кр╣Йр╕Бр╕▓р╕гр╕Ир╕│р╕ер╕нр╕З")
                embeddings = np.array([self._get_embedding(text) for text in job_texts])
            
            # р╕кр╕гр╣Йр╕▓р╕З FAISS index
            print(f"{Fore.CYAN}ЁЯУК р╕Бр╕│р╕ер╕▒р╕Зр╕кр╕гр╣Йр╕▓р╕З FAISS index...")
            
            dimension = embeddings.shape[1]
            index = faiss.IndexFlatL2(dimension)
            index.add(embeddings.astype(np.float32))
            
            # р╕кр╕гр╣Йр╕▓р╕З mapping р╕гр╕░р╕лр╕зр╣Ир╕▓р╕З job_id р╕Бр╕▒р╕Ъ index
            for i, job_id in enumerate(job_ids):
                job_ids_to_index[job_id] = i
            
            # р╕Ър╕▒р╕Щр╕Чр╕╢р╕Б FAISS index
            print(f"{Fore.CYAN}ЁЯТ╛ р╕Бр╕│р╕ер╕▒р╕Зр╕Ър╕▒р╕Щр╕Чр╕╢р╕Б FAISS index р╣Др╕Ыр╕Чр╕╡р╣И {self.job_index_path}...")
            faiss.write_index(index, str(self.job_index_path))
            
            # р╕Ър╕▒р╕Щр╕Чр╕╢р╕Б metadata
            print(f"{Fore.CYAN}ЁЯТ╛ р╕Бр╕│р╕ер╕▒р╕Зр╕Ър╕▒р╕Щр╕Чр╕╢р╕Б metadata р╣Др╕Ыр╕Чр╕╡р╣И {self.job_metadata_path}...")
            metadata = {
                "job_ids": job_ids,
                "job_ids_to_index": job_ids_to_index,
                "job_data": job_data
            }
            
            with open(self.job_metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            print(f"{Fore.GREEN}тЬЕ р╕кр╕гр╣Йр╕▓р╕З embeddings р╕кр╕│р╕лр╕гр╕▒р╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Юр╕кр╕│р╣Ар╕гр╣Зр╕И: {len(job_ids)} vectors")
            
            result["success"] = True
            result["vectors_count"] = len(job_ids)
            
            return result
            
        except Exception as e:
            print(f"{Fore.RED}тЭМ р╣Ар╕Бр╕┤р╕Фр╕Вр╣Йр╕нр╕Ьр╕┤р╕Фр╕Юр╕ер╕▓р╕Фр╣Гр╕Щр╕Бр╕▓р╕гр╕кр╕гр╣Йр╕▓р╕З embeddings р╕кр╕│р╕лр╕гр╕▒р╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Ю: {str(e)}")
            result["error"] = str(e)
            return result
    
    def create_advice_embeddings(self) -> Dict[str, Any]:
        """
        р╕кр╕гр╣Йр╕▓р╕З embeddings р╕кр╕│р╕лр╕гр╕▒р╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕нр╕▓р╕Кр╕╡р╕Юр╣Бр╕ер╕░р╕Ър╕▒р╕Щр╕Чр╕╢р╕Бр╕ер╕Зр╣Гр╕Щ FAISS
        
        Returns:
            р╕Ьр╕ер╕ер╕▒р╕Юр╕Шр╣Мр╕Вр╕нр╕Зр╕Бр╕▓р╕гр╕кр╕гр╣Йр╕▓р╕З embeddings
        """
        result = {
            "success": False,
            "vectors_count": 0,
            "error": None
        }
        
        try:
            # р╣Вр╕лр╕ер╕Фр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕нр╕▓р╕Кр╕╡р╕Ю
            advice_data = self._load_career_advice_data()
            
            if not advice_data:
                result["error"] = "р╣Др╕бр╣Ир╕Юр╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕нр╕▓р╕Кр╕╡р╕Ю"
                return result
            
            print(f"{Fore.CYAN}ЁЯФД р╕Бр╕│р╕ер╕▒р╕Зр╕кр╕гр╣Йр╕▓р╕З embeddings р╕кр╕│р╕лр╕гр╕▒р╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕нр╕▓р╕Кр╕╡р╕Ю {len(advice_data)} р╕гр╕▓р╕вр╕Бр╕▓р╕г...")
            
            # р╣Ар╕Хр╕гр╕╡р╕вр╕бр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕кр╕│р╕лр╕гр╕▒р╕Ър╕кр╕гр╣Йр╕▓р╕З embeddings
            advice_ids = []
            advice_texts = []
            advice_ids_to_index = {}
            
            for i, advice in enumerate(advice_data):
                # р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ъ ID
                if "id" not in advice:
                    advice["id"] = f"advice_{i}"
                
                advice_text = self._prepare_advice_text_for_embedding(advice)
                advice_texts.append(advice_text)
                advice_ids.append(advice["id"])
            
            # р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕е
            if not advice_texts:
                result["error"] = "р╣Др╕бр╣Ир╕кр╕▓р╕бр╕▓р╕гр╕Цр╣Ар╕Хр╕гр╕╡р╕вр╕бр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╕кр╕│р╕лр╕гр╕▒р╕Ър╕кр╕гр╣Йр╕▓р╕З embeddings р╣Др╕Фр╣Й"
                return result
            
            # р╕кр╕гр╣Йр╕▓р╕З embeddings
            print(f"{Fore.CYAN}ЁЯза р╕Бр╕│р╕ер╕▒р╕Зр╕кр╕гр╣Йр╕▓р╕З embeddings р╕Ир╕│р╕Щр╕зр╕Щ {len(advice_texts)} р╕гр╕▓р╕вр╕Бр╕▓р╕г...")
            
            if self.embedding_model:
                # р╣Гр╕Кр╣Йр╣Вр╕бр╣Ар╕Фр╕ер╕Ир╕гр╕┤р╕З
                embeddings = self.embedding_model.encode(advice_texts, show_progress_bar=True)
            else:
                # р╣Гр╕Кр╣Йр╕Бр╕▓р╕гр╕Ир╕│р╕ер╕нр╕З
                print(f"{Fore.YELLOW}тЪая╕П р╣Др╕бр╣Ир╕Юр╕Ър╣Вр╕бр╣Ар╕Фр╕е embedding р╕Ир╕░р╣Гр╕Кр╣Йр╕Бр╕▓р╕гр╕Ир╕│р╕ер╕нр╕З")
                embeddings = np.array([self._get_embedding(text) for text in advice_texts])
            
            # р╕кр╕гр╣Йр╕▓р╕З FAISS index
            print(f"{Fore.CYAN}ЁЯУК р╕Бр╕│р╕ер╕▒р╕Зр╕кр╕гр╣Йр╕▓р╕З FAISS index...")
            
            dimension = embeddings.shape[1]
            index = faiss.IndexFlatL2(dimension)
            index.add(embeddings.astype(np.float32))
            
            # р╕кр╕гр╣Йр╕▓р╕З mapping р╕гр╕░р╕лр╕зр╣Ир╕▓р╕З advice_id р╕Бр╕▒р╕Ъ index
            for i, advice_id in enumerate(advice_ids):
                advice_ids_to_index[advice_id] = i
            
            # р╕Ър╕▒р╕Щр╕Чр╕╢р╕Б FAISS index
            print(f"{Fore.CYAN}ЁЯТ╛ р╕Бр╕│р╕ер╕▒р╕Зр╕Ър╕▒р╕Щр╕Чр╕╢р╕Б FAISS index р╣Др╕Ыр╕Чр╕╡р╣И {self.advice_index_path}...")
            faiss.write_index(index, str(self.advice_index_path))
            
            # р╕Ър╕▒р╕Щр╕Чр╕╢р╕Б metadata
            print(f"{Fore.CYAN}ЁЯТ╛ р╕Бр╕│р╕ер╕▒р╕Зр╕Ър╕▒р╕Щр╕Чр╕╢р╕Б metadata р╣Др╕Ыр╕Чр╕╡р╣И {self.advice_metadata_path}...")
            
            # р╕кр╕гр╣Йр╕▓р╕Зр╕Вр╣Йр╕нр╕бр╕╣р╕е metadata р╕Чр╕╡р╣Ир╕Бр╕гр╕░р╕Кр╕▒р╕Ъ
            simplified_advice_data = []
            for advice in advice_data:
                simplified = {
                    "id": advice["id"],
                    "title": advice.get("title", ""),
                    "tags": advice.get("tags", []),
                    "source": advice.get("source", ""),
                    "url": advice.get("url", "")
                }
                
                # р╕Фр╕╢р╕Зр╣Ар╕Щр╕╖р╣Йр╕нр╕лр╕▓р╕нр╣Ир╕▓р╕Щр╕Зр╣Ир╕▓р╕вр╕кр╕│р╕лр╕гр╕▒р╕Ър╣Бр╕кр╕Фр╕Зр╕Ьр╕е
                if "content" in advice:
                    simplified["text"] = advice["content"][:500] + "..." if len(advice["content"]) > 500 else advice["content"]
                elif "paragraphs" in advice and advice["paragraphs"]:
                    joined_text = " ".join(advice["paragraphs"][:3])
                    simplified["text"] = joined_text[:500] + "..." if len(joined_text) > 500 else joined_text
                
                simplified_advice_data.append(simplified)
            
            metadata = {
                "advice_ids": advice_ids,
                "advice_ids_to_index": advice_ids_to_index,
                "advice_data": simplified_advice_data
            }
            
            with open(self.advice_metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            print(f"{Fore.GREEN}тЬЕ р╕кр╕гр╣Йр╕▓р╕З embeddings р╕кр╕│р╕лр╕гр╕▒р╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕нр╕▓р╕Кр╕╡р╕Юр╕кр╕│р╣Ар╕гр╣Зр╕И: {len(advice_ids)} vectors")
            
            result["success"] = True
            result["vectors_count"] = len(advice_ids)
            
            return result
            
        except Exception as e:
            print(f"{Fore.RED}тЭМ р╣Ар╕Бр╕┤р╕Фр╕Вр╣Йр╕нр╕Ьр╕┤р╕Фр╕Юр╕ер╕▓р╕Фр╣Гр╕Щр╕Бр╕▓р╕гр╕кр╕гр╣Йр╕▓р╕З embeddings р╕кр╕│р╕лр╕гр╕▒р╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕нр╕▓р╕Кр╕╡р╕Ю: {str(e)}")
            result["error"] = str(e)
            return result
    
    def create_all_embeddings(self) -> Dict[str, Any]:
        """
        р╕кр╕гр╣Йр╕▓р╕З embeddings р╕Чр╕▒р╣Йр╕Зр╕лр╕бр╕Ф р╕Чр╕▒р╣Йр╕Зр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Юр╣Бр╕ер╕░р╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕нр╕▓р╕Кр╕╡р╕Ю
        
        Returns:
            р╕Ьр╕ер╕ер╕▒р╕Юр╕Шр╣Мр╕Вр╕нр╕Зр╕Бр╕▓р╕гр╕кр╕гр╣Йр╕▓р╕З embeddings
        """
        print(f"{Fore.CYAN}{'='*60}")
        print(f"{Fore.CYAN}= р╣Ар╕гр╕┤р╣Ир╕бр╕Хр╣Йр╕Щр╕Бр╕▓р╕гр╕кр╕гр╣Йр╕▓р╕З Vector Database р╕Чр╕▒р╣Йр╕Зр╕лр╕бр╕Ф")
        print(f"{Fore.CYAN}{'='*60}")
        
        # р╕кр╕гр╣Йр╕▓р╕З embeddings р╕кр╕│р╕лр╕гр╕▒р╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Ю
        print(f"\n{Fore.CYAN}{'='*20} р╕кр╕гр╣Йр╕▓р╕З embeddings р╕кр╕│р╕лр╕гр╕▒р╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Ю {'='*20}")
        job_result = self.create_job_embeddings()
        
        # р╕кр╕гр╣Йр╕▓р╕З embeddings р╕кр╕│р╕лр╕гр╕▒р╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕нр╕▓р╕Кр╕╡р╕Ю
        print(f"\n{Fore.CYAN}{'='*20} р╕кр╕гр╣Йр╕▓р╕З embeddings р╕кр╕│р╕лр╕гр╕▒р╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕нр╕▓р╕Кр╕╡р╕Ю {'='*20}")
        advice_result = self.create_advice_embeddings()
        
        return {
            "job_embeddings": job_result,
            "advice_embeddings": advice_result
        }
    
    def search_similar_jobs(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """
        р╕Др╣Йр╕Щр╕лр╕▓р╕нр╕▓р╕Кр╕╡р╕Юр╕Чр╕╡р╣Ир╣Ар╕Бр╕╡р╣Ир╕вр╕зр╕Вр╣Йр╕нр╕Зр╕Бр╕▒р╕Ър╕Др╕│р╕Др╣Йр╕Щр╕лр╕▓
        
        Args:
            query: р╕Др╕│р╕Др╣Йр╕Щр╕лр╕▓
            k: р╕Ир╕│р╕Щр╕зр╕Щр╕Ьр╕ер╕ер╕▒р╕Юр╕Шр╣Мр╕Чр╕╡р╣Ир╕Хр╣Йр╕нр╕Зр╕Бр╕▓р╕г
            
        Returns:
            р╕гр╕▓р╕вр╕Бр╕▓р╕гр╕нр╕▓р╕Кр╕╡р╕Юр╕Чр╕╡р╣Ир╣Ар╕Бр╕╡р╣Ир╕вр╕зр╕Вр╣Йр╕нр╕З
        """
        # р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ър╕зр╣Ир╕▓ vector database р╕бр╕╡р╕нр╕вр╕╣р╣Ир╕Ир╕гр╕┤р╕З
        if not self.job_index_path.exists() or not self.job_metadata_path.exists():
            print(f"{Fore.RED}тЭМ р╣Др╕бр╣Ир╕Юр╕Ъ vector database р╕кр╕│р╕лр╕гр╕▒р╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Ю")
            return []
        
        try:
            # р╣Вр╕лр╕ер╕Ф FAISS index
            index = faiss.read_index(str(self.job_index_path))
            
            # р╣Вр╕лр╕ер╕Ф metadata
            with open(self.job_metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            # р╕кр╕гр╣Йр╕▓р╕З embedding р╕кр╕│р╕лр╕гр╕▒р╕Ър╕Др╕│р╕Др╣Йр╕Щр╕лр╕▓
            query_embedding = None
            if self.embedding_model:
                query_embedding = self.embedding_model.encode([query])[0]
            else:
                query_embedding = self._get_embedding(query)
            
            # р╕Др╣Йр╕Щр╕лр╕▓р╣Гр╕Щ FAISS
            query_embedding = np.array([query_embedding]).astype(np.float32)
            distances, indices = index.search(query_embedding, k)
            
            # р╣Бр╕Ыр╕ер╕Зр╕Ьр╕ер╕ер╕▒р╕Юр╕Шр╣М
            results = []
            for i, idx in enumerate(indices[0]):
                if idx == -1 or idx >= len(metadata["job_ids"]):
                    continue
                
                job_id = metadata["job_ids"][idx]
                job_data = None
                
                # р╕лр╕▓р╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Юр╕Ир╕▓р╕Б job_id
                for job in metadata["job_data"]:
                    if job["id"] == job_id:
                        job_data = job
                        break
                
                if job_data is None:
                    continue
                
                # р╕Др╕│р╕Щр╕зр╕Ур╕Др╕░р╣Бр╕Щр╕Щр╕Др╕зр╕▓р╕бр╕Др╕ер╣Йр╕▓р╕вр╕Др╕ер╕╢р╕З (1 - р╕гр╕░р╕вр╕░р╕Чр╕▓р╕З)
                similarity = 1.0 / (1.0 + distances[0][i])
                
                # р╕кр╕гр╣Йр╕▓р╕Зр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕кр╕│р╕лр╕гр╕▒р╕Ър╕Ьр╕ер╕ер╕▒р╕Юр╕Шр╣М
                result = {
                    "id": job_id,
                    "title": job_data["titles"][0] if job_data["titles"] else job_id,
                    "similarity": similarity,
                    "description": job_data.get("description", ""),
                    "responsibilities": job_data.get("responsibilities", []),
                    "skills": job_data.get("skills", []),
                }
                
                results.append(result)
                
                # р╣Бр╕кр╕Фр╕Зр╕Ьр╕е
                print(f"{i+1}. {Fore.GREEN}{result['title']}{Style.RESET_ALL} " + 
                     f"(р╕Др╕░р╣Бр╕Щр╕Щр╕Др╕зр╕▓р╕бр╣Ар╕лр╕бр╕╖р╕нр╕Щ: {Fore.YELLOW}{result['similarity']:.2f}{Style.RESET_ALL})")
            
            return results
        
        except Exception as e:
            print(f"{Fore.RED}тЭМ р╣Ар╕Бр╕┤р╕Фр╕Вр╣Йр╕нр╕Ьр╕┤р╕Фр╕Юр╕ер╕▓р╕Фр╣Гр╕Щр╕Бр╕▓р╕гр╕Др╣Йр╕Щр╕лр╕▓р╕нр╕▓р╕Кр╕╡р╕Ю: {str(e)}")
            return []
    
    def search_relevant_advices(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """
        р╕Др╣Йр╕Щр╕лр╕▓р╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕нр╕▓р╕Кр╕╡р╕Юр╕Чр╕╡р╣Ир╣Ар╕Бр╕╡р╣Ир╕вр╕зр╕Вр╣Йр╕нр╕Зр╕Бр╕▒р╕Ър╕Др╕│р╕Др╣Йр╕Щр╕лр╕▓
        
        Args:
            query: р╕Др╕│р╕Др╣Йр╕Щр╕лр╕▓
            k: р╕Ир╕│р╕Щр╕зр╕Щр╕Ьр╕ер╕ер╕▒р╕Юр╕Шр╣Мр╕Чр╕╡р╣Ир╕Хр╣Йр╕нр╕Зр╕Бр╕▓р╕г
            
        Returns:
            р╕гр╕▓р╕вр╕Бр╕▓р╕гр╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕нр╕▓р╕Кр╕╡р╕Юр╕Чр╕╡р╣Ир╣Ар╕Бр╕╡р╣Ир╕вр╕зр╕Вр╣Йр╕нр╕З
        """
        # р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ър╕зр╣Ир╕▓ vector database р╕бр╕╡р╕нр╕вр╕╣р╣Ир╕Ир╕гр╕┤р╕З
        if not self.advice_index_path.exists() or not self.advice_metadata_path.exists():
            print(f"{Fore.RED}тЭМ р╣Др╕бр╣Ир╕Юр╕Ъ vector database р╕кр╕│р╕лр╕гр╕▒р╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕нр╕▓р╕Кр╕╡р╕Ю")
            return []
        
        try:
            # р╣Вр╕лр╕ер╕Ф FAISS index
            index = faiss.read_index(str(self.advice_index_path))
            
            # р╣Вр╕лр╕ер╕Ф metadata
            with open(self.advice_metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            # р╕кр╕гр╣Йр╕▓р╕З embedding р╕кр╕│р╕лр╕гр╕▒р╕Ър╕Др╕│р╕Др╣Йр╕Щр╕лр╕▓
            query_embedding = None
            if self.embedding_model:
                query_embedding = self.embedding_model.encode([query])[0]
            else:
                query_embedding = self._get_embedding(query)
            
            # р╕Др╣Йр╕Щр╕лр╕▓р╣Гр╕Щ FAISS
            query_embedding = np.array([query_embedding]).astype(np.float32)
            distances, indices = index.search(query_embedding, k)
            
            # р╣Бр╕Ыр╕ер╕Зр╕Ьр╕ер╕ер╕▒р╕Юр╕Шр╣М
            results = []
            for i, idx in enumerate(indices[0]):
                if idx == -1 or idx >= len(metadata["advice_ids"]):
                    continue
                
                advice_id = metadata["advice_ids"][idx]
                advice_data = None
                
                # р╕лр╕▓р╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕Ир╕▓р╕Б advice_id
                for advice in metadata["advice_data"]:
                    if advice["id"] == advice_id:
                        advice_data = advice
                        break
                
                if advice_data is None:
                    continue
                
                # р╕Др╕│р╕Щр╕зр╕Ур╕Др╕░р╣Бр╕Щр╕Щр╕Др╕зр╕▓р╕бр╕Др╕ер╣Йр╕▓р╕вр╕Др╕ер╕╢р╕З (1 - р╕гр╕░р╕вр╕░р╕Чр╕▓р╕З)
                similarity = 1.0 / (1.0 + distances[0][i])
                
                # р╕кр╕гр╣Йр╕▓р╕Зр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕кр╕│р╕лр╕гр╕▒р╕Ър╕Ьр╕ер╕ер╕▒р╕Юр╕Шр╣М
                result = {
                    "id": advice_id,
                    "title": advice_data.get("title", ""),
                    "similarity": similarity,
                    "text": advice_data.get("text", ""),
                    "tags": advice_data.get("tags", []),
                    "source": advice_data.get("source", ""),
                    "url": advice_data.get("url", "")
                }
                
                results.append(result)
                
                # р╣Бр╕кр╕Фр╕Зр╕Ьр╕е
                tags_str = f", р╣Бр╕Чр╣Зр╕Б: {', '.join(result['tags'])}" if result['tags'] else ""
                print(f"{i+1}. {Fore.GREEN}{result['title']}{Style.RESET_ALL} " + 
                    f"(р╕Др╕░р╣Бр╕Щр╕Щр╕Др╕зр╕▓р╕бр╣Ар╕лр╕бр╕╖р╕нр╕Щ: {Fore.YELLOW}{result['similarity']:.2f}{Style.RESET_ALL}{tags_str})")
            
            return results
        
        except Exception as e:
            print(f"{Fore.RED}тЭМ р╣Ар╕Бр╕┤р╕Фр╕Вр╣Йр╕нр╕Ьр╕┤р╕Фр╕Юр╕ер╕▓р╕Фр╣Гр╕Щр╕Бр╕▓р╕гр╕Др╣Йр╕Щр╕лр╕▓р╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│: {str(e)}")
            return []

    def get_job_by_id(self, job_id: str) -> Optional[Dict[str, Any]]:
        """
        р╕Фр╕╢р╕Зр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Юр╣Вр╕Фр╕в ID
        
        Args:
            job_id: ID р╕Вр╕нр╕Зр╕нр╕▓р╕Кр╕╡р╕Юр╕Чр╕╡р╣Ир╕Хр╣Йр╕нр╕Зр╕Бр╕▓р╕г
            
        Returns:
            р╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Юр╕лр╕гр╕╖р╕н None р╕Цр╣Йр╕▓р╣Др╕бр╣Ир╕Юр╕Ъ
        """
        # р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ър╕зр╣Ир╕▓ metadata р╕бр╕╡р╕нр╕вр╕╣р╣Ир╕Ир╕гр╕┤р╕З
        if not self.job_metadata_path.exists():
            print(f"{Fore.RED}тЭМ р╣Др╕бр╣Ир╕Юр╕Ър╣Др╕Яр╕ер╣М metadata р╕кр╕│р╕лр╕гр╕▒р╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Ю")
            return None
        
        try:
            # р╣Вр╕лр╕ер╕Ф metadata
            with open(self.job_metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            # р╕лр╕▓р╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Юр╕Ир╕▓р╕Б job_id
            for job in metadata["job_data"]:
                if job["id"] == job_id:
                    return job
            
            print(f"{Fore.YELLOW}тЪая╕П р╣Др╕бр╣Ир╕Юр╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Юр╕кр╕│р╕лр╕гр╕▒р╕Ъ ID: {job_id}")
            return None
            
        except Exception as e:
            print(f"{Fore.RED}тЭМ р╣Ар╕Бр╕┤р╕Фр╕Вр╣Йр╕нр╕Ьр╕┤р╕Фр╕Юр╕ер╕▓р╕Фр╣Гр╕Щр╕Бр╕▓р╕гр╕Фр╕╢р╕Зр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Ю: {str(e)}")
            return None
    
    def get_advice_by_id(self, advice_id: str) -> Optional[Dict[str, Any]]:
        """
        р╕Фр╕╢р╕Зр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕нр╕▓р╕Кр╕╡р╕Юр╣Вр╕Фр╕в ID
        
        Args:
            advice_id: ID р╕Вр╕нр╕Зр╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕Чр╕╡р╣Ир╕Хр╣Йр╕нр╕Зр╕Бр╕▓р╕г
            
        Returns:
            р╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕лр╕гр╕╖р╕н None р╕Цр╣Йр╕▓р╣Др╕бр╣Ир╕Юр╕Ъ
        """
        # р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ър╕зр╣Ир╕▓ metadata р╕бр╕╡р╕нр╕вр╕╣р╣Ир╕Ир╕гр╕┤р╕З
        if not self.advice_metadata_path.exists():
            print(f"{Fore.RED}тЭМ р╣Др╕бр╣Ир╕Юр╕Ър╣Др╕Яр╕ер╣М metadata р╕кр╕│р╕лр╕гр╕▒р╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕нр╕▓р╕Кр╕╡р╕Ю")
            return None
        
        try:
            # р╣Вр╕лр╕ер╕Ф metadata
            with open(self.advice_metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            # р╕лр╕▓р╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕Ир╕▓р╕Б advice_id
            for advice in metadata["advice_data"]:
                if advice["id"] == advice_id:
                    return advice
            
            print(f"{Fore.YELLOW}тЪая╕П р╣Др╕бр╣Ир╕Юр╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕кр╕│р╕лр╕гр╕▒р╕Ъ ID: {advice_id}")
            return None
            
        except Exception as e:
            print(f"{Fore.RED}тЭМ р╣Ар╕Бр╕┤р╕Фр╕Вр╣Йр╕нр╕Ьр╕┤р╕Фр╕Юр╕ер╕▓р╕Фр╣Гр╕Щр╕Бр╕▓р╕гр╕Фр╕╢р╕Зр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│: {str(e)}")
            return None


# р╕Хр╕▒р╕зр╕нр╕вр╣Ир╕▓р╕Зр╕Бр╕▓р╕гр╣Гр╕Кр╣Йр╕Зр╕▓р╕Щ
if __name__ == "__main__":
    # р╕кр╕гр╣Йр╕▓р╕Зр╣Вр╕бр╣Ар╕Фр╕е SentenceTransformer (р╕Цр╣Йр╕▓р╕бр╕╡)
    model = None
    try:
        from sentence_transformers import SentenceTransformer
        print(f"{Fore.CYAN}ЁЯФД р╕Бр╕│р╕ер╕▒р╕Зр╣Вр╕лр╕ер╕Фр╣Вр╕бр╣Ар╕Фр╕е SentenceTransformer...")
        model = SentenceTransformer('intfloat/e5-small-v2')
        print(f"{Fore.GREEN}тЬЕ р╣Вр╕лр╕ер╕Фр╣Вр╕бр╣Ар╕Фр╕ер╕кр╕│р╣Ар╕гр╣Зр╕И")
    except Exception as e:
        print(f"{Fore.YELLOW}тЪая╕П р╣Др╕бр╣Ир╕кр╕▓р╕бр╕▓р╕гр╕Цр╣Вр╕лр╕ер╕Фр╣Вр╕бр╣Ар╕Фр╕ер╣Др╕Фр╣Й: {str(e)}")
        print(f"{Fore.YELLOW}тЪая╕П р╕Ир╕░р╣Гр╕Кр╣Йр╕Бр╕▓р╕гр╕Ир╕│р╕ер╕нр╕З embedding р╣Бр╕Чр╕Щ")
    
    # р╕Бр╕│р╕лр╕Щр╕Фр╕Юр╕▓р╕Шр╕Вр╕нр╕Зр╣Др╕Яр╕ер╣М
    processed_data_dir = "data/processed"
    vector_db_dir = "data/vector_db"
    
    try:
        print(f"{Fore.CYAN}{'='*60}")
        print(f"{Fore.CYAN}= р╕Чр╕Фр╕кр╕нр╕Ър╕Бр╕▓р╕гр╣Гр╕Кр╣Йр╕Зр╕▓р╕Щ VectorCreator")
        print(f"{Fore.CYAN}{'='*60}")
        
        # р╕кр╕гр╣Йр╕▓р╕З VectorCreator
        creator = VectorCreator(
            processed_data_dir=processed_data_dir,
            vector_db_dir=vector_db_dir,
            embedding_model=model,
            clear_vector_db=True  # р╕ер╣Йр╕▓р╕Зр╕Вр╣Йр╕нр╕бр╕╣р╕ер╣Ар╕Фр╕┤р╕бр╕Бр╣Ир╕нр╕Щр╕кр╕гр╣Йр╕▓р╕Зр╣Гр╕лр╕бр╣И
        )
        
        # р╕кр╕гр╣Йр╕▓р╕З embeddings р╕Чр╕▒р╣Йр╕Зр╕лр╕бр╕Ф
        results = creator.create_all_embeddings()
        
        # р╕Чр╕Фр╕кр╕нр╕Ър╕Бр╕▓р╕гр╕Др╣Йр╕Щр╕лр╕▓
        print(f"\n{Fore.CYAN}{'='*60}")
        print(f"{Fore.CYAN}= р╕Чр╕Фр╕кр╕нр╕Ър╕Бр╕▓р╕гр╕Др╣Йр╕Щр╕лр╕▓")
        print(f"{Fore.CYAN}{'='*60}")
        
        # р╕Чр╕Фр╕кр╕нр╕Ър╕Др╣Йр╕Щр╕лр╕▓р╕нр╕▓р╕Кр╕╡р╕Ю
        print(f"\n{Fore.CYAN}ЁЯФН р╕Чр╕Фр╕кр╕нр╕Ър╕Др╣Йр╕Щр╕лр╕▓р╕нр╕▓р╕Кр╕╡р╕Юр╕Чр╕╡р╣Ир╣Ар╕Бр╕╡р╣Ир╕вр╕зр╕Вр╣Йр╕нр╕Зр╕Бр╕▒р╕Ъ: 'р╕Щр╕▒р╕Бр╕Юр╕▒р╕Тр╕Щр╕▓р╕Лр╕нр╕Яр╕Хр╣Мр╣Бр╕зр╕гр╣М'{Style.RESET_ALL}")
        creator.search_similar_jobs("р╕Щр╕▒р╕Бр╕Юр╕▒р╕Тр╕Щр╕▓р╕Лр╕нр╕Яр╕Хр╣Мр╣Бр╕зр╕гр╣М", k=3)
        
        print(f"\n{Fore.CYAN}ЁЯФН р╕Чр╕Фр╕кр╕нр╕Ър╕Др╣Йр╕Щр╕лр╕▓р╕нр╕▓р╕Кр╕╡р╕Юр╕Чр╕╡р╣Ир╣Ар╕Бр╕╡р╣Ир╕вр╕зр╕Вр╣Йр╕нр╕Зр╕Бр╕▒р╕Ъ: 'р╕Бр╕▓р╕гр╕Ир╕▒р╕Фр╕Бр╕▓р╕гр╣Вр╕Др╕гр╕Зр╕Бр╕▓р╕г'{Style.RESET_ALL}")
        creator.search_similar_jobs("р╕Бр╕▓р╕гр╕Ир╕▒р╕Фр╕Бр╕▓р╕гр╣Вр╕Др╕гр╕Зр╕Бр╕▓р╕г", k=3)
        
        # р╕Чр╕Фр╕кр╕нр╕Ър╕Др╣Йр╕Щр╕лр╕▓р╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕нр╕▓р╕Кр╕╡р╕Ю
        print(f"\n{Fore.CYAN}ЁЯФН р╕Чр╕Фр╕кр╕нр╕Ър╕Др╣Йр╕Щр╕лр╕▓р╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕нр╕▓р╕Кр╕╡р╕Юр╕Чр╕╡р╣Ир╣Ар╕Бр╕╡р╣Ир╕вр╕зр╕Вр╣Йр╕нр╕Зр╕Бр╕▒р╕Ъ: 'р╕Бр╕▓р╕гр╣Ар╕Вр╕╡р╕вр╕Щ resume'{Style.RESET_ALL}")
        creator.search_relevant_advices("р╕Бр╕▓р╕гр╣Ар╕Вр╕╡р╕вр╕Щ resume", k=3)
        
        print(f"\n{Fore.CYAN}ЁЯФН р╕Чр╕Фр╕кр╕нр╕Ър╕Др╣Йр╕Щр╕лр╕▓р╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕нр╕▓р╕Кр╕╡р╕Юр╕Чр╕╡р╣Ир╣Ар╕Бр╕╡р╣Ир╕вр╕зр╕Вр╣Йр╕нр╕Зр╕Бр╕▒р╕Ъ: 'р╕Бр╕▓р╕гр╣Ар╕Хр╕гр╕╡р╕вр╕бр╕Хр╕▒р╕зр╕кр╕▒р╕бр╕ар╕▓р╕йр╕Ур╣Мр╕Зр╕▓р╕Щ'{Style.RESET_ALL}")
        creator.search_relevant_advices("р╕Бр╕▓р╕гр╣Ар╕Хр╕гр╕╡р╕вр╕бр╕Хр╕▒р╕зр╕кр╕▒р╕бр╕ар╕▓р╕йр╕Ур╣Мр╕Зр╕▓р╕Щ", k=3)
        
        print(f"\n{Fore.GREEN}тЬЕ р╕Чр╕Фр╕кр╕нр╕Ър╣Ар╕кр╕гр╣Зр╕Ир╕кр╕┤р╣Йр╕Щ")
        
    except Exception as e:
        print(f"{Fore.RED}тЭМ р╣Ар╕Бр╕┤р╕Фр╕Вр╣Йр╕нр╕Ьр╕┤р╕Фр╕Юр╕ер╕▓р╕Фр╣Гр╕Щр╕Бр╕▓р╕гр╕Чр╕Фр╕кр╕нр╕Ъ: {str(e)}")


    def create_combined_embeddings(self) -> Dict[str, Any]:
        """
        р╕кр╕гр╣Йр╕▓р╕З embeddings р╣Бр╕Ър╕Ър╕гр╕зр╕бр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Юр╣Бр╕ер╕░р╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╣Ар╕Вр╣Йр╕▓р╕Фр╣Йр╕зр╕вр╕Бр╕▒р╕Щ
        
        Returns:
            р╕Ьр╕ер╕ер╕▒р╕Юр╕Шр╣Мр╕Вр╕нр╕Зр╕Бр╕▓р╕гр╕кр╕гр╣Йр╕▓р╕З embeddings
        """
        result = {
            "success": False,
            "vectors_count": 0,
            "error": None
        }
        
        try:
            # р╣Вр╕лр╕ер╕Фр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Ю
            job_data = self._load_job_data()
            
            # р╣Вр╕лр╕ер╕Фр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│
            advice_data = self._load_career_advice_data()
            
            # р╣Вр╕лр╕ер╕Фр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Ьр╕╣р╣Йр╣Гр╕Кр╣Й
            user_data = self._load_user_data()
            
            if not job_data and not advice_data and not user_data:
                result["error"] = "р╣Др╕бр╣Ир╕Юр╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Ю, р╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│ р╣Бр╕ер╕░р╕Ьр╕╣р╣Йр╣Гр╕Кр╣Й"
                return result
            
            print(f"{Fore.CYAN}ЁЯФД р╕Бр╕│р╕ер╕▒р╕Зр╕кр╕гр╣Йр╕▓р╕З embeddings р╣Бр╕Ър╕Ър╕гр╕зр╕бр╕Вр╣Йр╕нр╕бр╕╣р╕е (р╕нр╕▓р╕Кр╕╡р╕Ю {len(job_data)} р╕гр╕▓р╕вр╕Бр╕▓р╕г, р╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│ {len(advice_data)} р╕гр╕▓р╕вр╕Бр╕▓р╕г, р╕Ьр╕╣р╣Йр╣Гр╕Кр╣Й {len(user_data)} р╕гр╕▓р╕вр╕Бр╕▓р╕г)...")
            
            # р╣Ар╕Хр╕гр╕╡р╕вр╕бр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕кр╕│р╕лр╕гр╕▒р╕Ър╕кр╕гр╣Йр╕▓р╕З embeddings
            combined_texts = []
            combined_ids = []
            combined_data = []
            combined_types = []  # р╣Ар╕Юр╕┤р╣Ир╕бр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Ыр╕гр╕░р╣Ар╕ар╕Ч ("job", "advice", "user")
            
            # р╣Ар╕Юр╕┤р╣Ир╕бр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Ю
            for job in job_data:
                if "id" not in job:
                    continue
                    
                job_text = self._prepare_job_text_for_embedding(job)
                job_id = f"job_{job['id']}"
                
                combined_texts.append(job_text)
                combined_ids.append(job_id)
                combined_data.append(job)
                combined_types.append("job")
            
            # р╣Ар╕Юр╕┤р╣Ир╕бр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│
            for advice in advice_data:
                if "id" not in advice:
                    continue
                    
                advice_text = self._prepare_advice_text_for_embedding(advice)
                advice_id = f"advice_{advice['id']}"
                
                combined_texts.append(advice_text)
                combined_ids.append(advice_id)
                combined_data.append(advice)
                combined_types.append("advice")
            
            # р╣Ар╕Юр╕┤р╣Ир╕бр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Ьр╕╣р╣Йр╣Гр╕Кр╣Й
            for user in user_data:
                if "id" not in user:
                    continue
                    
                user_text = self._prepare_user_text_for_embedding(user)
                user_id = f"user_{user['id']}"
                
                combined_texts.append(user_text)
                combined_ids.append(user_id)
                combined_data.append(user)
                combined_types.append("user")
            
            # р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕е
            if not combined_texts:
                result["error"] = "р╣Др╕бр╣Ир╕кр╕▓р╕бр╕▓р╕гр╕Цр╣Ар╕Хр╕гр╕╡р╕вр╕бр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╕кр╕│р╕лр╕гр╕▒р╕Ър╕кр╕гр╣Йр╕▓р╕З embeddings р╣Др╕Фр╣Й"
                return result
            
            # р╕кр╕гр╣Йр╕▓р╕З embeddings
            print(f"{Fore.CYAN}ЁЯза р╕Бр╕│р╕ер╕▒р╕Зр╕кр╕гр╣Йр╕▓р╕З embeddings р╕Ир╕│р╕Щр╕зр╕Щ {len(combined_texts)} р╕гр╕▓р╕вр╕Бр╕▓р╕г...")
            
            if self.embedding_model:
                # р╣Гр╕Кр╣Йр╣Вр╕бр╣Ар╕Фр╕ер╕Ир╕гр╕┤р╕З
                embeddings = self.embedding_model.encode(combined_texts, show_progress_bar=True)
            else:
                # р╣Гр╕Кр╣Йр╕Бр╕▓р╕гр╕Ир╕│р╕ер╕нр╕З
                print(f"{Fore.YELLOW}тЪая╕П р╣Др╕бр╣Ир╕Юр╕Ър╣Вр╕бр╣Ар╕Фр╕е embedding р╕Ир╕░р╣Гр╕Кр╣Йр╕Бр╕▓р╕гр╕Ир╕│р╕ер╕нр╕З")
                embeddings = np.array([self._get_embedding(text) for text in combined_texts])
            
            # р╕кр╕гр╣Йр╕▓р╕З FAISS index
            print(f"{Fore.CYAN}ЁЯУК р╕Бр╕│р╕ер╕▒р╕Зр╕кр╕гр╣Йр╕▓р╕З FAISS index...")
            
            dimension = embeddings.shape[1]
            index = faiss.IndexFlatL2(dimension)
            index.add(embeddings.astype(np.float32))
            
            # р╕кр╕гр╣Йр╕▓р╕З mapping р╕гр╕░р╕лр╕зр╣Ир╕▓р╕З id р╕Бр╕▒р╕Ъ index
            combined_ids_to_index = {}
            for i, item_id in enumerate(combined_ids):
                combined_ids_to_index[item_id] = i
            
            # р╕кр╕гр╣Йр╕▓р╕Зр╣Вр╕Яр╕ер╣Ар╕Фр╕нр╕гр╣Мр╕кр╕│р╕лр╕гр╕▒р╕Ър╣Ар╕Бр╣Зр╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕гр╕зр╕б
            combined_vector_dir = self.vector_db_dir / "combined_knowledge"
            combined_vector_dir.mkdir(parents=True, exist_ok=True)
            
            # р╕Ър╕▒р╕Щр╕Чр╕╢р╕Б FAISS index
            combined_index_path = combined_vector_dir / "faiss_index.bin"
            print(f"{Fore.CYAN}ЁЯТ╛ р╕Бр╕│р╕ер╕▒р╕Зр╕Ър╕▒р╕Щр╕Чр╕╢р╕Б FAISS index р╣Др╕Ыр╕Чр╕╡р╣И {combined_index_path}...")
            faiss.write_index(index, str(combined_index_path))
            
            # р╕Ър╕▒р╕Щр╕Чр╕╢р╕Б metadata
            combined_metadata_path = combined_vector_dir / "metadata.json"
            print(f"{Fore.CYAN}ЁЯТ╛ р╕Бр╕│р╕ер╕▒р╕Зр╕Ър╕▒р╕Щр╕Чр╕╢р╕Б metadata р╣Др╕Ыр╕Чр╕╡р╣И {combined_metadata_path}...")
            
            # р╕Ыр╕гр╕▒р╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╣Гр╕лр╣Йр╕бр╕╡р╕Вр╕Щр╕▓р╕Фр╣Ар╕ер╣Зр╕Бр╕ер╕Зр╕кр╕│р╕лр╕гр╕▒р╕Ър╣Ар╕Бр╣Зр╕Ър╣Гр╕Щ metadata
            simplified_items = []
            for i, item in enumerate(combined_data):
                item_type = combined_types[i]
                simplified_item = {"id": combined_ids[i], "type": item_type}
                
                if item_type == "job":
                    simplified_item.update({
                        "title": item.get("titles", [""])[0] if isinstance(item.get("titles"), list) and item.get("titles") else "",
                        "description": item.get("description", "")[:300] + "..." if len(item.get("description", "")) > 300 else item.get("description", ""),
                        "responsibilities": item.get("responsibilities", [])[:3],
                        "skills": item.get("skills", [])[:5],
                        "salary_ranges": item.get("salary_ranges", [])
                    })
                elif item_type == "advice":
                    simplified_item.update({
                        "title": item.get("title", ""),
                        "text_preview": item.get("text", "")[:300] + "..." if len(item.get("text", "")) > 300 else item.get("text", ""),
                        "tags": item.get("tags", []),
                        "source": item.get("source", ""),
                        "url": item.get("url", "")
                    })
                elif item_type == "user":
                    simplified_item.update({
                        "name": item.get("name", ""),
                        "institution": item.get("institution", ""),
                        "education_status": item.get("education_status", ""),
                        "skills": [skill.get("name") for skill in item.get("skills", [])][:5] if isinstance(item.get("skills"), list) else [],
                        "programming_languages": item.get("programming_languages", [])[:5] if isinstance(item.get("programming_languages"), list) else []
                    })
                
                simplified_items.append(simplified_item)
            
            metadata = {
                "item_ids": combined_ids,
                "item_types": combined_types,
                "item_ids_to_index": combined_ids_to_index,
                "item_data": simplified_items
            }
            
            with open(combined_metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            print(f"{Fore.GREEN}тЬЕ р╕кр╕гр╣Йр╕▓р╕З embeddings р╣Бр╕Ър╕Ър╕гр╕зр╕бр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕кр╕│р╣Ар╕гр╣Зр╕И: {len(combined_ids)} vectors")
            
            result["success"] = True
            result["vectors_count"] = len(combined_ids)
            
            return result
            
        except Exception as e:
            print(f"{Fore.RED}тЭМ р╣Ар╕Бр╕┤р╕Фр╕Вр╣Йр╕нр╕Ьр╕┤р╕Фр╕Юр╕ер╕▓р╕Фр╣Гр╕Щр╕Бр╕▓р╕гр╕кр╕гр╣Йр╕▓р╕З embeddings р╣Бр╕Ър╕Ър╕гр╕зр╕бр╕Вр╣Йр╕нр╕бр╕╣р╕е: {str(e)}")
            result["error"] = str(e)
            return result
        
    def _prepare_user_text_for_embedding(self, user: Dict[str, Any]) -> str:
        """
        р╣Ар╕Хр╕гр╕╡р╕вр╕бр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╕Ир╕▓р╕Бр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Ьр╕╣р╣Йр╣Гр╕Кр╣Йр╕кр╕│р╕лр╕гр╕▒р╕Ър╕кр╕гр╣Йр╕▓р╕З embedding
        
        Args:
            user: р╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Ьр╕╣р╣Йр╣Гр╕Кр╣Й
            
        Returns:
            р╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╕Чр╕╡р╣Ир╕Юр╕гр╣Йр╕нр╕бр╕кр╕│р╕лр╕гр╕▒р╕Ър╕кр╕гр╣Йр╕▓р╕З embedding
        """
        text_parts = []
        
        # р╣Ар╕Юр╕┤р╣Ир╕бр╕Кр╕╖р╣Ир╕нр╕Ьр╕╣р╣Йр╣Гр╕Кр╣Й
        if "name" in user and user["name"]:
            text_parts.append(f"р╕Кр╕╖р╣Ир╕н: {user['name']}")
        
        # р╣Ар╕Юр╕┤р╣Ир╕бр╕кр╕Цр╕▓р╕Ър╕▒р╕Щр╕Бр╕▓р╕гр╕ир╕╢р╕Бр╕йр╕▓
        if "institution" in user and user["institution"]:
            text_parts.append(f"р╕кр╕Цр╕▓р╕Ър╕▒р╕Щр╕Бр╕▓р╕гр╕ир╕╢р╕Бр╕йр╕▓: {user['institution']}")
        
        # р╣Ар╕Юр╕┤р╣Ир╕бр╕кр╕Цр╕▓р╕Щр╕░р╕Бр╕▓р╕гр╕ир╕╢р╕Бр╕йр╕▓
        if "education_status" in user and user["education_status"]:
            status_mapping = {
                "student": "р╕Бр╕│р╕ер╕▒р╕Зр╕ир╕╢р╕Бр╕йр╕▓",
                "graduate": "р╕Ир╕Ър╕Бр╕▓р╕гр╕ир╕╢р╕Бр╕йр╕▓",
                "working": "р╕Чр╕│р╕Зр╕▓р╕Щр╣Бр╕ер╣Йр╕з",
                "other": "р╕нр╕╖р╣Ир╕Щр╣Ж"
            }
            status = status_mapping.get(user["education_status"], user["education_status"])
            text_parts.append(f"р╕кр╕Цр╕▓р╕Щр╕░: {status}")
        
        # р╣Ар╕Юр╕┤р╣Ир╕бр╕Кр╕▒р╣Йр╕Щр╕Ыр╕╡
        if "year" in user and user["year"]:
            text_parts.append(f"р╕Кр╕▒р╣Йр╕Щр╕Ыр╕╡: {user['year']}")
        
        # р╣Ар╕Юр╕┤р╣Ир╕бр╕Чр╕▒р╕Бр╕йр╕░
        if "skills" in user and user["skills"]:
            skills_text = []
            for skill in user["skills"]:
                if isinstance(skill, dict):
                    skill_name = skill.get("name", "")
                    skill_level = skill.get("proficiency", 0)
                    if skill_name:
                        skills_text.append(f"{skill_name} (р╕гр╕░р╕Фр╕▒р╕Ъ {skill_level}/5)")
                elif isinstance(skill, str):
                    skills_text.append(skill)
            
            if skills_text:
                text_parts.append(f"р╕Чр╕▒р╕Бр╕йр╕░: {', '.join(skills_text)}")
        
        # р╣Ар╕Юр╕┤р╣Ир╕бр╕ар╕▓р╕йр╕▓р╣Вр╕Ыр╕гр╣Бр╕Бр╕гр╕б
        if "programming_languages" in user and user["programming_languages"]:
            text_parts.append(f"р╕ар╕▓р╕йр╕▓р╣Вр╕Ыр╕гр╣Бр╕Бр╕гр╕б: {', '.join(user['programming_languages'])}")
        
        # р╣Ар╕Юр╕┤р╣Ир╕бр╣Ар╕Др╕гр╕╖р╣Ир╕нр╕Зр╕бр╕╖р╕н
        if "tools" in user and user["tools"]:
            text_parts.append(f"р╣Ар╕Др╕гр╕╖р╣Ир╕нр╕Зр╕бр╕╖р╕н: {', '.join(user['tools'])}")
        
        # р╣Ар╕Юр╕┤р╣Ир╕бр╣Вр╕Ыр╕гр╣Ар╕Ир╕Бр╕Хр╣М
        if "projects" in user and user["projects"]:
            projects_text = []
            for project in user["projects"]:
                project_name = project.get("name", "")
                project_desc = project.get("description", "")
                project_tech = project.get("technologies", [])
                
                if project_name:
                    project_text = project_name
                    if project_desc:
                        project_text += f" - {project_desc}"
                    if project_tech:
                        project_text += f" (р╣Ар╕Чр╕Др╣Вр╕Щр╣Вр╕ер╕вр╕╡: {', '.join(project_tech)})"
                    projects_text.append(project_text)
            
            if projects_text:
                text_parts.append(f"р╣Вр╕Ыр╕гр╣Ар╕Ир╕Бр╕Хр╣М: {'; '.join(projects_text)}")
        
        # р╣Ар╕Юр╕┤р╣Ир╕бр╕Ыр╕гр╕░р╕кр╕Ър╕Бр╕▓р╕гр╕Ур╣Мр╕Чр╕│р╕Зр╕▓р╕Щ
        if "work_experiences" in user and user["work_experiences"]:
            work_text = []
            for work in user["work_experiences"]:
                work_title = work.get("title", "")
                work_company = work.get("company", "")
                work_start = work.get("start_date", "")
                work_end = work.get("end_date", "")
                work_desc = work.get("description", "")
                
                if work_title and work_company:
                    exp_text = f"{work_title} р╕Чр╕╡р╣И {work_company}"
                    if work_start:
                        exp_text += f" ({work_start}"
                        if work_end:
                            exp_text += f" р╕Цр╕╢р╕З {work_end}"
                        exp_text += ")"
                    if work_desc:
                        exp_text += f" - {work_desc}"
                    work_text.append(exp_text)
            
            if work_text:
                text_parts.append(f"р╕Ыр╕гр╕░р╕кр╕Ър╕Бр╕▓р╕гр╕Ур╣М: {'; '.join(work_text)}")
        
        # р╕гр╕зр╕бр╕Чр╕╕р╕Бр╕кр╣Ир╕зр╕Щр╣Ар╕Вр╣Йр╕▓р╕Фр╣Йр╕зр╕вр╕Бр╕▒р╕Щ
        return " ".join(text_parts)

    def _load_user_data(self) -> List[Dict[str, Any]]:
        """
        р╣Вр╕лр╕ер╕Фр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Ьр╕╣р╣Йр╣Гр╕Кр╣Йр╕Чр╕▒р╣Йр╕Зр╕лр╕бр╕Фр╕Ир╕▓р╕Бр╣Др╕Яр╕ер╣М users.json
        
        Returns:
            List р╕Вр╕нр╕Зр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Ьр╕╣р╣Йр╣Гр╕Кр╣Й
        """
        try:
            from src.utils.config import USERS_DIR
            users_file = os.path.join(USERS_DIR, "users.json")
            
            if os.path.exists(users_file):
                with open(users_file, 'r', encoding='utf-8') as f:
                    users_data = json.load(f)
                    
                    # р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ър╣Вр╕Др╕гр╕Зр╕кр╕гр╣Йр╕▓р╕Зр╕Вр╣Йр╕нр╕бр╕╣р╕е
                    if isinstance(users_data, list):
                        print(f"{Fore.GREEN}тЬЕ р╣Вр╕лр╕ер╕Фр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Ьр╕╣р╣Йр╣Гр╕Кр╣Йр╕кр╕│р╣Ар╕гр╣Зр╕И: {len(users_data)} р╕гр╕▓р╕вр╕Бр╕▓р╕г")
                        return users_data
                    else:
                        print(f"{Fore.YELLOW}тЪая╕П р╕гр╕╣р╕Ыр╣Бр╕Ър╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Ьр╕╣р╣Йр╣Гр╕Кр╣Йр╣Др╕бр╣Ир╕Цр╕╣р╕Бр╕Хр╣Йр╕нр╕З р╕Др╕зр╕гр╣Ар╕Ыр╣Зр╕Щр╕гр╕▓р╕вр╕Бр╕▓р╕г (List)")
                        return []
            else:
                print(f"{Fore.YELLOW}тЪая╕П р╣Др╕бр╣Ир╕Юр╕Ър╣Др╕Яр╕ер╣Мр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Ьр╕╣р╣Йр╣Гр╕Кр╣Й: {users_file}")
                return []
        except Exception as e:
            print(f"{Fore.RED}тЭМ р╣Ар╕Бр╕┤р╕Фр╕Вр╣Йр╕нр╕Ьр╕┤р╕Фр╕Юр╕ер╕▓р╕Фр╣Гр╕Щр╕Бр╕▓р╕гр╣Вр╕лр╕ер╕Фр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Ьр╕╣р╣Йр╣Гр╕Кр╣Й: {str(e)}")
            return []

    def create_all_embeddings(self) -> Dict[str, Any]:
        """
        р╕кр╕гр╣Йр╕▓р╕З embeddings р╕Чр╕▒р╣Йр╕Зр╕лр╕бр╕Ф р╕Чр╕▒р╣Йр╕Зр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Юр╣Бр╕ер╕░р╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕нр╕▓р╕Кр╕╡р╕Ю р╣Бр╕ер╕░р╕Вр╣Йр╕нр╕бр╕╣р╕ер╕гр╕зр╕б
        
        Returns:
            р╕Ьр╕ер╕ер╕▒р╕Юр╕Шр╣Мр╕Вр╕нр╕Зр╕Бр╕▓р╕гр╕кр╕гр╣Йр╕▓р╕З embeddings
        """
        print(f"{Fore.CYAN}{'='*60}")
        print(f"{Fore.CYAN}= р╣Ар╕гр╕┤р╣Ир╕бр╕Хр╣Йр╕Щр╕Бр╕▓р╕гр╕кр╕гр╣Йр╕▓р╕З Vector Database р╕Чр╕▒р╣Йр╕Зр╕лр╕бр╕Ф")
        print(f"{Fore.CYAN}{'='*60}")
        
        # р╕кр╕гр╣Йр╕▓р╕З embeddings р╕кр╕│р╕лр╕гр╕▒р╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Ю
        print(f"\n{Fore.CYAN}{'='*20} р╕кр╕гр╣Йр╕▓р╕З embeddings р╕кр╕│р╕лр╕гр╕▒р╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Кр╕╡р╕Ю {'='*20}")
        job_result = self.create_job_embeddings()
        
        # р╕кр╕гр╣Йр╕▓р╕З embeddings р╕кр╕│р╕лр╕гр╕▒р╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕нр╕▓р╕Кр╕╡р╕Ю
        print(f"\n{Fore.CYAN}{'='*20} р╕кр╕гр╣Йр╕▓р╕З embeddings р╕кр╕│р╕лр╕гр╕▒р╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕нр╕▓р╕Кр╕╡р╕Ю {'='*20}")
        advice_result = self.create_advice_embeddings()
        
        # р╕кр╕гр╣Йр╕▓р╕З embeddings р╣Бр╕Ър╕Ър╕гр╕зр╕бр╕Вр╣Йр╕нр╕бр╕╣р╕е
        print(f"\n{Fore.CYAN}{'='*20} р╕кр╕гр╣Йр╕▓р╕З embeddings р╣Бр╕Ър╕Ър╕гр╕зр╕бр╕Вр╣Йр╕нр╕бр╕╣р╕е {'='*20}")
        combined_result = self.create_combined_embeddings()
        
        return {
            "job_embeddings": job_result,
            "advice_embeddings": advice_result,
            "combined_embeddings": combined_result
        }