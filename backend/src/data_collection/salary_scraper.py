#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import json
import logging
import argparse
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Set, Any, Optional
from urllib3.exceptions import InsecureRequestWarning

import requests
from bs4 import BeautifulSoup
from bs4.element import Tag
from tqdm import tqdm
import colorama

# ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô colorama
colorama.init()

# ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô SSL ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ SSL ‡πÑ‡∏î‡πâ
requests.packages.urllib3.disable_warnings(category=InsecureRequestWarning)

# ‡∏™‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÉ‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡∏°‡∏¥‡∏ô‡∏±‡∏•
class Colors:
    HEADER = '\033[95m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'
    GREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏•‡πá‡∏≠‡∏Å
log_dir = Path("logs")
log_dir.mkdir(parents=True, exist_ok=True)

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡πá‡∏≠‡∏Å
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_dir / "salary_scraper.log", encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger("salary_scraper")

class ISMTechSalaryScraper:
    def __init__(self, url: str = "https://www.ismtech.net/th/it-salary-report/", 
                 output_folder: str = "data/raw/other_sources", 
                 filename: str = "it_salary_data.json",
                 timeout: int = 30):
        self.base_url = url
        self.output_folder = output_folder
        self.filename = filename
        self.timeout = timeout
        self.json_file_path = os.path.join(output_folder, filename)
        self.summary_file_path = os.path.join(output_folder, "salary_summary.md")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå output ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
        Path(self.output_folder).mkdir(parents=True, exist_ok=True)
        
        # Header ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏Ç‡∏≠ HTTP
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Accept-Language": "th-TH,th;q=0.9,en-US;q=0.8,en;q=0.7",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Referer": "https://www.google.com/",
            "Connection": "keep-alive"
        }
        
        # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤
        self.job_data = {}
    
    def backup_existing_file(self) -> None:
        if os.path.exists(self.json_file_path):
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_file = f"{os.path.splitext(self.json_file_path)[0]}_{timestamp}.json"
            
            try:
                import shutil
                shutil.copy2(self.json_file_path, backup_file)
                logger.info(f"‡∏™‡∏≥‡∏£‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà: {backup_file}")
                print(f"{Colors.CYAN}üìã ‡∏™‡∏≥‡∏£‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà: {backup_file}{Colors.ENDC}")
            except Exception as e:
                logger.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏≥‡∏£‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏î‡πâ: {str(e)}")
                print(f"{Colors.FAIL}‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏≥‡∏£‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏î‡πâ: {str(e)}{Colors.ENDC}")
    
    def fetch_page(self) -> Optional[BeautifulSoup]:
        try:
            logger.info(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å {self.base_url}")
            print(f"{Colors.CYAN}üåê ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å {self.base_url}{Colors.ENDC}")
            
            response = requests.get(
                self.base_url, 
                headers=self.headers, 
                timeout=self.timeout,
                verify=False
            )
            response.encoding = 'utf-8'
            
            if response.status_code != 200:
                logger.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞: {response.status_code}")
                print(f"{Colors.FAIL}‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå! ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞: {response.status_code}{Colors.ENDC}")
                return None
            
            logger.info("‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            print(f"{Colors.GREEN}‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à{Colors.ENDC}")
            return BeautifulSoup(response.text, "html.parser")
            
        except requests.exceptions.Timeout:
            logger.error(f"‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏´‡∏°‡∏î‡πÄ‡∏ß‡∏•‡∏≤ (timeout) ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å {self.timeout} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")
            print(f"{Colors.FAIL}‚ùå ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏´‡∏°‡∏î‡πÄ‡∏ß‡∏•‡∏≤ (timeout) ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å {self.timeout} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ{Colors.ENDC}")
            return None
        except requests.exceptions.ConnectionError:
            logger.error("‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠")
            print(f"{Colors.FAIL}‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠{Colors.ENDC}")
            return None
        except Exception as e:
            logger.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {str(e)}")
            print(f"{Colors.FAIL}‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {str(e)}{Colors.ENDC}")
            return None
    
    def extract_salary_data(self, soup: BeautifulSoup) -> Dict[str, Any]:
        try:
            logger.info("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô")
            print(f"{Colors.CYAN}üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô...{Colors.ENDC}")
            
            # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
            job_titles = [title.text.strip() for title in soup.find_all(class_="entry-title")]
            logger.info(f"‡∏û‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(job_titles)} ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á")
            print(f"{Colors.GREEN}‚úì ‡∏û‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(job_titles)} ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á{Colors.ENDC}")
            
            # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ
            job_skills = [skill.text.strip() for skill in soup.find_all(class_="entry-skill")]
            logger.info(f"‡∏û‡∏ö‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(job_skills)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
            print(f"{Colors.GREEN}‚úì ‡∏û‡∏ö‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(job_skills)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£{Colors.ENDC}")
            
            # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
            salary_tables = soup.find_all("div", class_="entry-summary")
            logger.info(f"‡∏û‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(salary_tables)} ‡∏ï‡∏≤‡∏£‡∏≤‡∏á")
            print(f"{Colors.GREEN}‚úì ‡∏û‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(salary_tables)} ‡∏ï‡∏≤‡∏£‡∏≤‡∏á{Colors.ENDC}")
            
            # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
            job_data = {}
            
            # ‡πÉ‡∏ä‡πâ tqdm ‡∏™‡∏£‡πâ‡∏≤‡∏á progress bar ‡∏ó‡∏µ‡πà‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏°
            for index, table in enumerate(tqdm(salary_tables, desc="üìä ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô", unit="job")):
                job_name = job_titles[index] if index < len(job_titles) else f"‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà {index+1}"
                skills = job_skills[index] if index < len(job_skills) else "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡∏Å‡∏©‡∏∞"
                
                # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ñ‡∏ß‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
                salary_raw = []
                tbody = table.find("tbody")
                
                if tbody:
                    rows = tbody.find_all("tr")
                    
                    for row in rows:
                        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Ç‡∏≠‡∏á <tr> ‡πÄ‡∏õ‡πá‡∏ô 1 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î (‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏î‡πâ‡∏ß‡∏¢ " | ")
                        cells = row.find_all("td")
                        if cells:
                            row_text = " | ".join(cell.text.strip() for cell in cells)
                            
                            if row_text:
                                salary_raw.append(row_text)  # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡∏Å‡πà‡∏≠‡∏ô
                
                # ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏π‡πà (‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå, ‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)
                salary_list = []
                salary_set: Set[Tuple[str, str]] = set()  # ‡πÉ‡∏ä‡πâ set() ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡πà‡∏≤‡∏ã‡πâ‡∏≥
                
                for raw_text in salary_raw:
                    parts = raw_text.split(" | ")  # ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å "|"
                    
                    for i in range(0, len(parts), 2):
                        if i + 1 < len(parts):  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏π‡πà
                            exp_part = parts[i].strip()
                            salary_part = parts[i + 1].strip()
                            
                            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                            if exp_part and salary_part and self._validate_salary_data(exp_part, salary_part):
                                salary_entry = (exp_part, salary_part)
                                
                                if salary_entry not in salary_set:  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡πà‡∏≤‡∏ã‡πâ‡∏≥
                                    salary_set.add(salary_entry)
                                    salary_list.append({
                                        "experience": exp_part, 
                                        "salary": salary_part
                                    })
                
                # ‡∏à‡∏±‡∏î‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á dictionary
                job_data[job_name] = {
                    "skills": skills,
                    "salary": salary_list
                }
            
            logger.info(f"‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à {len(job_data)} ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á")
            print(f"{Colors.GREEN}‚úÖ ‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à {len(job_data)} ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á{Colors.ENDC}")
            
            self.job_data = job_data
            return job_data
            
        except Exception as e:
            logger.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô: {str(e)}")
            print(f"{Colors.FAIL}‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô: {str(e)}{Colors.ENDC}")
            return {}
    
    def _validate_salary_data(self, experience: str, salary: str) -> bool:
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏á
        if not experience or not salary:
            return False
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏£‡πà‡∏≤‡∏ß‡πÜ ‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
        if '-' not in experience or '-' not in salary:
            return False
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
        # ‡πÄ‡∏ä‡πà‡∏ô ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        if not any(c.isdigit() for c in experience) or not any(c.isdigit() for c in salary):
            return False
        
        return True
    
    def save_to_json(self) -> bool:
        if not self.job_data:
            logger.error("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å")
            print(f"{Colors.FAIL}‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å{Colors.ENDC}")
            return False
        
        try:
            logger.info(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå {self.json_file_path}")
            print(f"{Colors.CYAN}üìù ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå {self.json_file_path}{Colors.ENDC}")
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏´‡∏≤‡∏Å‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
            os.makedirs(os.path.dirname(self.json_file_path), exist_ok=True)
            
            with open(self.json_file_path, "w", encoding="utf-8") as file:
                json.dump(self.job_data, file, indent=4, ensure_ascii=False)
            
            logger.info("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå JSON ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            print(f"{Colors.GREEN}‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå JSON ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à{Colors.ENDC}")
            return True
            
        except Exception as e:
            logger.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå JSON: {str(e)}")
            print(f"{Colors.FAIL}‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå JSON: {str(e)}{Colors.ENDC}")
            return False
    
    def create_summary_file(self) -> bool:
        if not self.job_data:
            logger.error("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏™‡∏£‡∏∏‡∏õ")
            print(f"{Colors.FAIL}‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏™‡∏£‡∏∏‡∏õ{Colors.ENDC}")
            return False
        
        try:
            logger.info(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏£‡∏∏‡∏õ {self.summary_file_path}")
            print(f"{Colors.CYAN}üìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏£‡∏∏‡∏õ {self.summary_file_path}{Colors.ENDC}")
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏´‡∏≤‡∏Å‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
            os.makedirs(os.path.dirname(self.summary_file_path), exist_ok=True)
            
            with open(self.summary_file_path, "w", encoding="utf-8") as file:
                file.write("# ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÉ‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤ IT\n\n")
                file.write(f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å: [{self.base_url}]({self.base_url})\n\n")
                file.write(f"‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                file.write(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(self.job_data)}\n\n")
                
                for job_title, job_info in self.job_data.items():
                    file.write(f"## {job_title}\n\n")
                    
                    if job_info["skills"]:
                        file.write(f"**‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£:** {job_info['skills']}\n\n")
                    
                    file.write("**‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô:**\n\n")
                    
                    for salary_info in job_info["salary"]:
                        file.write(f"- {salary_info['experience']}: {salary_info['salary']}\n")
                    
                    file.write("\n---\n\n")
            
            logger.info("‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            print(f"{Colors.GREEN}‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à{Colors.ENDC}")
            return True
            
        except Exception as e:
            logger.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏£‡∏∏‡∏õ: {str(e)}")
            print(f"{Colors.FAIL}‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏£‡∏∏‡∏õ: {str(e)}{Colors.ENDC}")
            return False
    
    def scrape(self) -> Dict[str, Any]:
        print(f"\n{Colors.BOLD}{Colors.HEADER}===== ISM Tech Salary Scraper ====={Colors.ENDC}\n")
        
        # ‡∏™‡∏≥‡∏£‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏°
        self.backup_existing_file()
        
        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå
        soup = self.fetch_page()
        if not soup:
            return {
                "success": False,
                "error": "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡πÑ‡∏î‡πâ",
                "jobs_count": 0
            }
        
        # ‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
        salary_data = self.extract_salary_data(soup)
        if not salary_data:
            return {
                "success": False,
                "error": "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÑ‡∏î‡πâ",
                "jobs_count": 0
            }
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå JSON
        json_result = self.save_to_json()
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏£‡∏∏‡∏õ
        summary_result = self.create_summary_file()
        
        return {
            "success": json_result and summary_result,
            "jobs_count": len(salary_data),
            "json_file": self.json_file_path,
            "summary_file": self.summary_file_path,
            "json_saved": json_result,
            "summary_saved": summary_result
        }


def main():
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏¢‡∏Å‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡πå‡∏Å‡∏¥‡∏ß‡πÄ‡∏°‡∏ô‡∏ï‡πå
    parser = argparse.ArgumentParser(description='‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô IT ‡∏à‡∏≤‡∏Å ISM Technology')
    parser.add_argument('-u', '--url', type=str, default="https://www.ismtech.net/th/it-salary-report/",
                        help='URL ‡∏Ç‡∏≠‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•')
    parser.add_argument('-o', '--output', type=str, default="data/raw/other_sources",
                        help='‡∏û‡∏≤‡∏ò‡∏Ç‡∏≠‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå')
    parser.add_argument('-f', '--filename', type=str, default="it_salary_data.json",
                        help='‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå JSON ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå')
    parser.add_argument('-t', '--timeout', type=int, default=30,
                        help='‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡∏°‡∏î‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ (‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)')
    parser.add_argument('-v', '--verbose', action='store_true',
                        help='‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÇ‡∏î‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î')
    
    # ‡πÅ‡∏¢‡∏Å‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡πå‡∏Å‡∏¥‡∏ß‡πÄ‡∏°‡∏ô‡∏ï‡πå
    args = parser.parse_args()
    
    # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡πá‡∏≠‡∏Å
    if args.verbose:
        logger.setLevel(logging.DEBUG)
        for handler in logger.handlers:
            handler.setLevel(logging.DEBUG)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏ô‡∏ï‡∏±‡∏ß‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    scraper = ISMTechSalaryScraper(args.url, args.output, args.filename, args.timeout)
    result = scraper.scrape()
    
    # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
    print(f"\n{Colors.BOLD}{Colors.HEADER}===== ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ====={Colors.ENDC}")
    print(f"{Colors.CYAN}üëâ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏û‡∏ö: {Colors.BOLD}{result['jobs_count']}{Colors.ENDC}")
    print(f"{Colors.CYAN}üëâ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå JSON: {Colors.GREEN if result.get('json_saved', False) else Colors.FAIL}{'‚úì' if result.get('json_saved', False) else '‚úó'}{Colors.ENDC}")
    print(f"{Colors.CYAN}üëâ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏£‡∏∏‡∏õ: {Colors.GREEN if result.get('summary_saved', False) else Colors.FAIL}{'‚úì' if result.get('summary_saved', False) else '‚úó'}{Colors.ENDC}")
    
    if result["success"]:
        print(f"{Colors.CYAN}üëâ ‡πÑ‡∏ü‡∏•‡πå JSON: {Colors.BOLD}{result.get('json_file', '')}{Colors.ENDC}")
        print(f"{Colors.CYAN}üëâ ‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏£‡∏∏‡∏õ: {Colors.BOLD}{result.get('summary_file', '')}{Colors.ENDC}")
        print(f"{Colors.CYAN}üëâ ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°: {Colors.GREEN}‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‚úì{Colors.ENDC}")
    else:
        print(f"{Colors.CYAN}üëâ ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {Colors.FAIL}{result.get('error', '‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏')}{Colors.ENDC}")
        print(f"{Colors.CYAN}üëâ ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°: {Colors.FAIL}‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‚úó{Colors.ENDC}")


if __name__ == "__main__":
    main()